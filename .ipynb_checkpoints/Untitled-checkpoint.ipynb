{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0e2992",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T10:00:26.655693Z",
     "start_time": "2023-06-02T10:00:01.589419Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.parametrizations import orthogonal\n",
    "from torch.nn import functional as F\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "from dataprep import transform_indices, full_preproccessing\n",
    "from utils import *\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "# %%\n",
    "# answer = binary matrix (no ratings)\n",
    "# answer = binary matrix (no ratings)\n",
    "class MVDataset(Dataset):\n",
    "    def __init__(self, data, data_description, augment=False):\n",
    "        useridx = data[data_description['users']].values\n",
    "        itemidx = data[data_description['items']].values\n",
    "        feedbackidx = data[data_description['feedback']].values\n",
    "        values = np.ones(len(itemidx), dtype=np.float32)\n",
    "        self.n_items = data_description['n_items']\n",
    "        self.n_ratings = data_description['n_ratings']\n",
    "        \n",
    "        self.tensor = torch.sparse_coo_tensor(np.array([useridx, itemidx, feedbackidx-1]), torch.tensor(values),\n",
    "                                            size=torch.Size((data_description[\"n_users\"], data_description[\"n_items\"], data_description['n_ratings'])))\n",
    "        self.matrix = torch.sparse_coo_tensor(np.array([useridx, itemidx]), torch.tensor(values),\n",
    "                                      size=torch.Size((data_description[\"n_users\"], data_description[\"n_items\"])), dtype=torch.float32)\n",
    "        \n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensor.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.augment:\n",
    "            num_noise = np.random.randint(0, int(0.1 * self.tensor.shape[1]))\n",
    "            idxs = torch.randint(0, self.tensor.shape[1], size=(num_noise,))\n",
    "            noised_input = self.tensor[idx].detach().clone().to_dense()\n",
    "            noised_input[idxs] = 0\n",
    "\n",
    "            itemidx = np.arange(self.tensor.shape[1])\n",
    "            ratingidx = np.arange(self.tensor.shape[2])\n",
    "            itemidx, ratingidx = np.meshgrid(itemidx, ratingidx)\n",
    "            noised_input = torch.sparse_coo_tensor(np.array([itemidx.flatten(), ratingidx.T.flatten(),]),\n",
    "                                                   noised_input.flatten(),\n",
    "                                                   size=torch.Size((self.n_items, self.n_ratings,)),\n",
    "                                                   dtype=torch.float32)\n",
    "            return noised_input, self.matrix[idx]\n",
    "        else:\n",
    "            return self.tensor[idx], self.matrix[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49079f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T10:00:31.695637Z",
     "start_time": "2023-06-02T10:00:29.403785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6040 users\n",
      "Filtered 93 invalid observations.\n",
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(42)\n",
    "data = pd.read_csv('ml-1m.csv')\n",
    "data.rename(columns={'userId': 'userid', 'movieId': 'movieid'}, inplace=True)\n",
    "\n",
    "# %%\n",
    "training, testset_valid, holdout_valid, testset, holdout, data_description, data_index = full_preproccessing(data)\n",
    "# %%\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4654217",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T10:01:29.355855Z",
     "start_time": "2023-06-02T10:01:29.316859Z"
    },
    "code_folding": [
     0,
     5,
     12,
     63
    ]
   },
   "outputs": [],
   "source": [
    "def triu_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        with torch.no_grad():\n",
    "            m.weight.copy_(torch.tril(m.weight))\n",
    "\n",
    "def get_zero_grad_hook(mask):\n",
    "    def hook(grad):\n",
    "        return grad * mask\n",
    "\n",
    "    return hook\n",
    "\n",
    "# %%\n",
    "class varindtriangularAE(nn.Module):\n",
    "    def __init__(self, n_items, n_ratings, hid1, hid2):\n",
    "        super(varindtriangularAE, self).__init__()\n",
    "        self.V = nn.Linear(n_items, hid1, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(self.V.weight)\n",
    "        self.VT = nn.Linear(hid1, n_items, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(self.VT.weight)\n",
    "        self.W = nn.Linear(n_ratings, hid2, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(self.W.weight)\n",
    "        self.WT = nn.Linear(hid2, n_ratings, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(self.WT.weight)\n",
    "        self.L = nn.Linear(n_ratings, n_ratings, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(self.L.weight)\n",
    "        triu_init(self.L)\n",
    "        self.LTinv = nn.Linear(n_ratings, n_ratings, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(self.LTinv.weight)\n",
    "        triu_init(self.LTinv)\n",
    "\n",
    "        #         self.norm = nn.LayerNorm(n_ratings)\n",
    "        self.vec = nn.Linear(n_items, 1)\n",
    "        torch.nn.init.xavier_uniform_(self.vec.weight)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "        # encode\n",
    "        x = self.L(input)\n",
    "        x = self.relu(x)\n",
    "        x = self.W(x)\n",
    "        x = self.relu(x)\n",
    "        xT = torch.transpose(x, -1, -2)\n",
    "        yT = self.V(xT)\n",
    "        y = torch.transpose(yT, -1, -2)\n",
    "        y = self.relu(y)\n",
    "        # decode\n",
    "        output = self.WT(y)\n",
    "        output = self.relu(output)\n",
    "        output = self.LTinv(output)\n",
    "        output = self.relu(output)\n",
    "        outputT = torch.transpose(output, -1, -2)\n",
    "        outputT = self.VT(outputT)\n",
    "        output = torch.transpose(outputT, -1, -2)\n",
    "\n",
    "        #         output = self.relu(output)\n",
    "        # vec\n",
    "        inputT = torch.transpose(input, -1, -2)\n",
    "        rating_layer = self.vec(inputT)\n",
    "        output = torch.matmul(output, rating_layer).squeeze(-1)\n",
    "        return output\n",
    "\n",
    "# %%\n",
    "def varindtriangular_model(h, data_description, device):\n",
    "    h1, h2 = h\n",
    "    ae = varindtriangularAE(data_description['n_items'], data_description['n_ratings'], h1, h2).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "    optimizer = optim.Adam(ae.parameters())\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "    mask = torch.tril(torch.ones_like(ae.L.weight))\n",
    "    ae.L.weight.register_hook(get_zero_grad_hook(mask))\n",
    "\n",
    "    mask = torch.tril(torch.ones_like(ae.LTinv.weight))\n",
    "    ae.LTinv.weight.register_hook(get_zero_grad_hook(mask))\n",
    "\n",
    "    return ae, criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f99021bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T10:03:11.562522Z",
     "start_time": "2023-06-02T10:02:49.329522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 3\n",
      "Hidden sizes: (512, 5)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.66 GiB (GPU 0; 4.00 GiB total capacity; 137.03 MiB already allocated; 701.60 MiB free; 1.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35508\\2350440118.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Alpha: 3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m training_testing_pipeline_augment(training, testset_valid, holdout_valid, testset, holdout, data_description,\n\u001b[0m\u001b[0;32m      4\u001b[0m                                   varindtriangular_model, h, device, MVDataset, batch_size=256, tensor_model=True)\n",
      "\u001b[1;32mD:\\GitHub\\Thesis_2023\\utils.py\u001b[0m in \u001b[0;36mtraining_testing_pipeline_augment\u001b[1;34m(training, testset_valid, holdout_valid, testset, holdout, data_description, model_init, h, device, MVDataset, tensor_model, batch_size, early_stop, n_epochs)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 656\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    657\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.66 GiB (GPU 0; 4.00 GiB total capacity; 137.03 MiB already allocated; 701.60 MiB free; 1.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "print('Alpha: 3')\n",
    "h = (512, 5)\n",
    "training_testing_pipeline_augment(training, testset_valid, holdout_valid, testset, holdout, data_description,\n",
    "                                  varindtriangular_model, h, device, MVDataset, batch_size=256, tensor_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0fe53f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
