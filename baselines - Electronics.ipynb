{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a6cea2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:55:46.207529Z",
     "start_time": "2023-04-13T19:55:28.039528Z"
    },
    "code_folding": [
     13
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.linalg import norm\n",
    "from IPython.display import clear_output\n",
    "from IPython.utils import io\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from urllib import request\n",
    "import tempfile\n",
    "import gzip\n",
    "from ast import literal_eval\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from polara.lib.tensor import hooi\n",
    "# from polara.lib.sparse import tensor_outer_at\n",
    "\n",
    "from dataprep import transform_indices, full_preproccessing\n",
    "from utils import topn_recommendations, downvote_seen_items, make_prediction, model_evaluate\n",
    "# from RecVAE.utils import *\n",
    "# from RecVAE.model import VAE as RecVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64dde154",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T11:46:08.455759Z",
     "start_time": "2023-03-18T11:46:08.437744Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def fix_torch_seed(seed, conv_determinism=True):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # settings below may affect computational performance\n",
    "    # see https://pytorch.org/docs/stable/notes/randomness.html:\n",
    "    if conv_determinism:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def set_random_seed(seed):\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# fix_torch_seed(42)\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a766d87d",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c0a49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:55:50.789531Z",
     "start_time": "2023-04-13T19:55:49.906536Z"
    },
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "# def amazon_data_reader(path):\n",
    "#     with gzip.open(path, 'rt') as gz:\n",
    "#         for line in gz:\n",
    "#             yield literal_eval(line)\n",
    "\n",
    "# def read_amazon_data(path=None, name=None):\n",
    "#     '''Data is taken from https://jmcauley.ucsd.edu/data/amazon/'''\n",
    "#     if path is None and name is None:\n",
    "#             raise ValueError('Either the name of the dataset to download \\\n",
    "#                 or a path to a local file must be specified.')\n",
    "#     if path is None:\n",
    "#         file_url = f'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_{name}_5.json.gz'\n",
    "#         print(f'Downloading data from: {file_url}')\n",
    "#         with request.urlopen(file_url) as response:\n",
    "#             file = response.read()\n",
    "#             with tempfile.NamedTemporaryFile(delete=False) as temp:\n",
    "#                 temp.write(file)\n",
    "#                 path = temp.name\n",
    "#                 print(f'Temporarily saved file at: {path}')\n",
    "#     data = pd.DataFrame.from_records(\n",
    "#         amazon_data_reader(path),\n",
    "#         columns=['reviewerID', 'asin', 'overall', 'unixReviewTime']\n",
    "#     )\n",
    "#     data.to_csv(f'Amazon_{name}.csv', index=None)\n",
    "#     return data\n",
    "\n",
    "# data = read_amazon_data(name = \"Electronics\")\n",
    "# data.rename(columns = {'reviewerID' : 'userid', 'asin' : 'movieid', \"overall\" : \"rating\", \"unixReviewTime\" : \"timestamp\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "614fb7b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T11:46:33.701634Z",
     "start_time": "2023-03-18T11:46:32.518638Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Amazon_Electronics.csv')\n",
    "data.rename(columns = {'reviewerID' : 'userid', 'asin' : 'movieid', \"overall\" : \"rating\", \"unixReviewTime\" : \"timestamp\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd32a931",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T11:46:44.162784Z",
     "start_time": "2023-03-18T11:46:35.899856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 192403 users\n",
      "Filtered 34993 invalid observations.\n"
     ]
    }
   ],
   "source": [
    "training, testset_valid, holdout_valid, testset, holdout, data_description, data_index = full_preproccessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951a2eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T11:46:44.843481Z",
     "start_time": "2023-03-18T11:46:44.781477Z"
    }
   },
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec12dc75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T11:37:24.734633Z",
     "start_time": "2023-03-15T11:37:24.218604Z"
    }
   },
   "outputs": [],
   "source": [
    "# alpha = 4\n",
    "# a = training[training['rating']>=alpha][['userid', 'movieid']]\n",
    "# a.columns = ['uid', 'sid']\n",
    "# a.to_csv(\"train.csv\", index=None)\n",
    "# b = testset_valid[(testset_valid['rating']>=alpha)&(testset_valid['movieid'].isin(training['movieid']))][['userid', 'movieid']]\n",
    "# b.columns = ['uid', 'sid']\n",
    "# b.to_csv(\"validation_tr.csv\", index=None)\n",
    "# c = holdout_valid[(holdout_valid['rating']>=alpha)&(holdout_valid['movieid'].isin(training['movieid']))&(holdout_valid['userid'].isin(testset_valid['userid']))][['userid', 'movieid']]\n",
    "# c.columns = ['uid', 'sid']\n",
    "# c.to_csv(\"validation_te.csv\", index=None)\n",
    "# d = testset[(testset['rating']>=alpha)&(testset['movieid'].isin(training['movieid']))][['userid', 'movieid']]\n",
    "# d.columns = ['uid', 'sid']\n",
    "# d.to_csv(\"test_tr.csv\", index=None)\n",
    "# e = holdout[(holdout['rating']>=alpha)&(holdout['movieid'].isin(training['movieid']))&(holdout['userid'].isin(testset['userid']))][['userid', 'movieid']]\n",
    "# e.columns = ['uid', 'sid']\n",
    "# e.to_csv(\"test_te.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d164f",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f5b040",
   "metadata": {},
   "source": [
    "## TopPop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1efeadd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T11:46:48.175812Z",
     "start_time": "2023-03-18T11:46:48.166455Z"
    },
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "def build_popularity_model(trainset, trainset_description):\n",
    "    itemid = trainset_description['items']\n",
    "    item_popularity = trainset[itemid].value_counts()\n",
    "    return item_popularity\n",
    "\n",
    "def popularity_model_scoring(params, testset, testset_description):\n",
    "    item_popularity = params\n",
    "    n_items = item_popularity.index.max() + 1\n",
    "    n_users = testset_description['n_test_users']\n",
    "    # fill in popularity scores for each item with indices from 0 to n_items-1\n",
    "    popularity_scores = np.zeros(n_items,)\n",
    "    popularity_scores[item_popularity.index] = item_popularity.values\n",
    "    # same scores for each test user\n",
    "    scores = np.tile(popularity_scores, n_users).reshape(n_users, n_items)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3459acd",
   "metadata": {},
   "source": [
    "## Normalized PureSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6573d3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T11:01:32.189186Z",
     "start_time": "2023-03-18T11:01:32.169165Z"
    },
    "code_folding": [
     0,
     6,
     16
    ]
   },
   "outputs": [],
   "source": [
    "def matrix_from_observations(data, data_description):\n",
    "    useridx = data[data_description['users']]\n",
    "    itemidx = data[data_description['items']]\n",
    "    values = data[data_description['feedback']]\n",
    "    return csr_matrix((values, (useridx, itemidx)), shape=(useridx.values.max() + 1, data_description[\"n_items\"]), dtype='f8')\n",
    "\n",
    "def build_svd_model(config, data, data_description):\n",
    "    source_matrix = matrix_from_observations(data, data_description)\n",
    "    #print(source_matrix.shape)\n",
    "    D = norm(source_matrix, axis=0)\n",
    "    A = source_matrix.dot(diags(D**(config['f']-1)))\n",
    "    _, _, vt = svds(A, k=config['rank'], return_singular_vectors='vh')\n",
    "#     singular_values = s[::-1]\n",
    "    item_factors = np.ascontiguousarray(vt[::-1, :].T)\n",
    "    return item_factors\n",
    "\n",
    "def svd_model_scoring(params, data, data_description):\n",
    "    item_factors = params\n",
    "    test_data = data.assign(\n",
    "        userid = pd.factorize(data['userid'])[0]\n",
    "    )\n",
    "    test_matrix = matrix_from_observations(test_data, data_description)\n",
    "    #print(test_matrix.shape, item_factors.shape)\n",
    "    scores = test_matrix.dot(item_factors) @ item_factors.T\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db38f88",
   "metadata": {},
   "source": [
    "## EASEr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3400353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T11:37:03.962853Z",
     "start_time": "2023-03-18T11:37:03.940178Z"
    },
    "code_folding": [
     0,
     6,
     17
    ]
   },
   "outputs": [],
   "source": [
    "def matrix_from_observations(data, data_description):\n",
    "    useridx = data[data_description['users']]\n",
    "    itemidx = data[data_description['items']]\n",
    "    values = data[data_description['feedback']]\n",
    "    return csr_matrix((values, (useridx, itemidx)), shape=(useridx.values.max() + 1, data_description[\"n_items\"]), dtype='f8')\n",
    "\n",
    "def easer(data, data_description, lmbda=500):\n",
    "    X = matrix_from_observations(data, data_description)\n",
    "    G = X.T.dot(X)\n",
    "    diag_indices = np.diag_indices(G.shape[0])\n",
    "    G[diag_indices] += lmbda\n",
    "    P = np.linalg.inv(G.A)\n",
    "    B = P / (-np.diag(P))\n",
    "    B[diag_indices] = 0\n",
    "    \n",
    "    return B\n",
    "\n",
    "def easer_scoring(params, data, data_description):\n",
    "    item_factors = params\n",
    "    test_data = data.assign(\n",
    "        userid = pd.factorize(data['userid'])[0]\n",
    "    )\n",
    "    test_matrix = matrix_from_observations(test_data, data_description)\n",
    "    scores = test_matrix.dot(item_factors)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a21cc5",
   "metadata": {},
   "source": [
    "## CoFFee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f5f89a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T10:59:15.495179Z",
     "start_time": "2023-03-18T10:59:15.471183Z"
    },
    "code_folding": [
     0,
     24
    ]
   },
   "outputs": [],
   "source": [
    "def tf_model_build(config, data, data_description):\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    idx = data[[userid, itemid, feedback]].values\n",
    "    idx[:, -1] = idx[:, -1] - data_description['min_rating'] # works only for integer ratings!\n",
    "    val = np.ones(idx.shape[0], dtype='f8')\n",
    "    \n",
    "    n_users = data_description[\"n_users\"]\n",
    "    n_items = data_description[\"n_items\"]\n",
    "    n_ratings = data_description[\"n_ratings\"]\n",
    "    shape = (n_users, n_items, n_ratings)\n",
    "    core_shape = config['mlrank']\n",
    "    num_iters = config[\"num_iters\"]\n",
    "    \n",
    "    u0, u1, u2, g = hooi(\n",
    "        idx, val, shape, core_shape,\n",
    "        num_iters=num_iters,\n",
    "        parallel_ttm=False, growth_tol=0.01,\n",
    "    )\n",
    "    return u0, u1, u2\n",
    "        \n",
    "\n",
    "def tf_scoring(params, data, data_description):\n",
    "    user_factors, item_factors, feedback_factors = params\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    data = data.sort_values(userid)\n",
    "    useridx = data[userid].values\n",
    "    itemidx = data[itemid].values\n",
    "    ratings = data[feedback].values\n",
    "    ratings = ratings - data_description['min_rating'] # works only for integer ratings!\n",
    "    \n",
    "    tensor_outer = tensor_outer_at('cpu')\n",
    "    # use the fact that test data is sorted by users for reduction:\n",
    "    scores = tensor_outer(\n",
    "        1.0,\n",
    "        item_factors,\n",
    "        feedback_factors,\n",
    "        itemidx,\n",
    "        ratings\n",
    "    )\n",
    "    scores = np.add.reduceat(scores, np.r_[0, np.where(np.diff(useridx))[0]+1])\n",
    "    scores = np.tensordot(\n",
    "        scores,\n",
    "        feedback_factors[-1, :],\n",
    "        axes=(2, 0)\n",
    "    ).dot(item_factors.T)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb73016",
   "metadata": {},
   "source": [
    "## RecVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "913c6190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T10:46:52.870443Z",
     "start_time": "2023-03-15T10:46:52.809899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2490400"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = RecVAE(600, 200, 1000)\n",
    "sum(p.numel() for p in vae.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb43703f",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15644cdd",
   "metadata": {},
   "source": [
    "## Normalized PureSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89ab9696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T10:59:18.439300Z",
     "start_time": "2023-03-18T10:59:18.426275Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "rank_grid = []\n",
    "for i in range(5, 10):\n",
    "    rank_grid.append(2 * 2 ** i)\n",
    "    rank_grid.append(3 * 2 ** i)\n",
    "    \n",
    "rank_grid = np.array(rank_grid)\n",
    "\n",
    "f_grid = np.linspace(0, 2, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78685dd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T10:59:56.843059Z",
     "start_time": "2023-03-18T10:59:20.623053Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "hr_tf = {}\n",
    "mrr_tf = {}\n",
    "grid = list(zip(np.meshgrid(rank_grid, f_grid)[0].flatten(), np.meshgrid(rank_grid, f_grid)[1].flatten()))\n",
    "for params in tqdm(grid):\n",
    "    r, f = params\n",
    "    svd_config = {'rank': int(r), 'f': f}\n",
    "    svd_params = build_svd_model(svd_config, training, data_description)\n",
    "    svd_scores = svd_model_scoring(svd_params, testset_valid, data_description)\n",
    "    downvote_seen_items(svd_scores, testset_valid, data_description)\n",
    "    svd_recs = topn_recommendations(svd_scores, topn=10)\n",
    "    hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(svd_recs, holdout_valid, data_description)\n",
    "    hr_tf[f'r={r}, f={f:.2f}'] = hr\n",
    "    mrr_tf[f'r={r}, f={f:.2f}'] = mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e935a2",
   "metadata": {},
   "source": [
    "## EASEr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5de163de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T11:37:07.259730Z",
     "start_time": "2023-03-18T11:37:07.242731Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_grid = np.arange(10, 510, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2c7a561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T11:37:17.702078Z",
     "start_time": "2023-03-18T11:37:17.408221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58351bbdf124b30be0428bc5b626158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 26.0 GiB for an array with shape (59065, 59065) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16024\\2532733472.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmrr_tf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlmbda\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambda_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0measer_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0measer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0measer_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0measer_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0measer_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestset_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_description\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdownvote_seen_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0measer_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestset_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_description\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16024\\202205867.py\u001b[0m in \u001b[0;36measer\u001b[1;34m(data, data_description, lmbda)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdiag_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdiag_indices\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mP\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdiag_indices\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    753\u001b[0m                     \u001b[1;34m\"Please use `.todense()` instead\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                 ))\n\u001b[1;32m--> 755\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'T'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 26.0 GiB for an array with shape (59065, 59065) and data type float64"
     ]
    }
   ],
   "source": [
    "hr_tf = {}\n",
    "mrr_tf = {}\n",
    "for lmbda in tqdm(lambda_grid):\n",
    "    easer_params = easer(training, data_description, lmbda=lmbda)\n",
    "    easer_scores = easer_scoring(easer_params, testset_valid, data_description)\n",
    "    downvote_seen_items(easer_scores, testset_valid, data_description)\n",
    "    easer_recs = topn_recommendations(easer_scores, topn=10)\n",
    "    hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(easer_recs, holdout_valid, data_description)\n",
    "    hr_tf[lmbda] = hr\n",
    "    mrr_tf[lmbda] = mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68036ac8",
   "metadata": {},
   "source": [
    "## CoFFee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "340cbfec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T07:54:39.799707Z",
     "start_time": "2023-03-15T07:54:39.787733Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"scaling\": 1,\n",
    "    \"n_ratings\": data_description['n_ratings'],\n",
    "    \"num_iters\": 4,\n",
    "    \"params\": None,\n",
    "    \"randomized\": True,\n",
    "    \"growth_tol\": 1e-4,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "grid1 = 2**np.arange(4, 12)\n",
    "grid2 = np.arange(2, 5)\n",
    "grid = np.meshgrid(grid1, grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53a658b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T05:10:13.056097Z",
     "start_time": "2023-03-14T18:04:03.705111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c73822aed34917bcc38cbe33158a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "growth of the core: 1.0\n",
      "growth of the core: 0.17108376145578136\n",
      "growth of the core: 0.013724276626127477\n",
      "growth of the core: 0.002121752668025982\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.1944648491989059\n",
      "growth of the core: 0.02467704747273349\n",
      "growth of the core: 0.005981755700370528\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.16282144181882102\n",
      "growth of the core: 0.029912952116613767\n",
      "growth of the core: 0.013916498704220537\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.23035313236669488\n",
      "growth of the core: 0.034784826568450604\n",
      "growth of the core: 0.011006067169166954\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.17594728189169354\n",
      "growth of the core: 0.030919135038606764\n",
      "growth of the core: 0.008959802437981649\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.1619910003475919\n",
      "growth of the core: 0.025820893734533307\n",
      "growth of the core: 0.008684790230411127\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.19297251628357556\n",
      "growth of the core: 0.0166869500789291\n",
      "growth of the core: 0.002735988699718407\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.03365805809426123\n",
      "growth of the core: 0.0008554701181437297\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.18773021057361874\n",
      "growth of the core: 0.023485580886369872\n",
      "growth of the core: 0.002659556048777158\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.16512210868559962\n",
      "growth of the core: 0.017278446629316057\n",
      "growth of the core: 0.004602445609099242\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.15929073359665435\n",
      "growth of the core: 0.025305541756806483\n",
      "growth of the core: 0.0078376026165582\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.16186025603337792\n",
      "growth of the core: 0.029482781213242534\n",
      "growth of the core: 0.008479828949641123\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.18356884139666396\n",
      "growth of the core: 0.027622863356177967\n",
      "growth of the core: 0.006383339883576526\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.14756299088392333\n",
      "growth of the core: 0.01598896146257266\n",
      "growth of the core: 0.0029837460381056456\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.07797536394350588\n",
      "growth of the core: 0.0057760244850739466\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.02484645102380898\n",
      "growth of the core: 0.00032360705597963115\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.1546311128986518\n",
      "growth of the core: 0.011421921104295407\n",
      "growth of the core: 0.0014350922061708313\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.15019894761489438\n",
      "growth of the core: 0.01476013323060603\n",
      "growth of the core: 0.0035170418715658102\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.1412237555895496\n",
      "growth of the core: 0.017331407447011334\n",
      "growth of the core: 0.0051468849070099715\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.13931418099261722\n",
      "growth of the core: 0.019110758182288252\n",
      "growth of the core: 0.005454518632815006\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.15165213874775577\n",
      "growth of the core: 0.021250598195627295\n",
      "growth of the core: 0.005190066626399523\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.09112532372673275\n",
      "growth of the core: 0.007363870609810213\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.06379321183703744\n",
      "growth of the core: 0.0029658054249700632\n",
      "Done\n",
      "growth of the core: 1.0\n",
      "growth of the core: 0.015562310916317443\n",
      "growth of the core: 0.0001331197749348139\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hr_tf = {}\n",
    "mrr_tf = {}\n",
    "for r12, r3 in tqdm(zip(grid[0].flatten(), grid[1].flatten()), total=24):\n",
    "    config['mlrank'] = (r12, r12, r3)\n",
    "    tf_params = tf_model_build(config, training, data_description)\n",
    "    tf_scores = tf_scoring(tf_params, testset_valid, data_description)\n",
    "    downvote_seen_items(tf_scores, testset_valid, data_description)\n",
    "    tf_recs = topn_recommendations(tf_scores, topn=10)\n",
    "    hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(tf_recs, holdout_valid, data_description)\n",
    "    hr_tf[(r12, r3)] = hr\n",
    "    mrr_tf[(r12, r3)] = mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68a0c8e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T06:54:41.000976Z",
     "start_time": "2023-03-15T06:54:40.980625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(16, 2): 0.05102639296187683,\n",
       " (32, 2): 0.05689149560117302,\n",
       " (64, 2): 0.06099706744868035,\n",
       " (128, 2): 0.05337243401759531,\n",
       " (256, 2): 0.06862170087976541,\n",
       " (512, 2): 0.031085043988269796,\n",
       " (1024, 2): 0.021114369501466276,\n",
       " (2048, 2): 0.008211143695014663,\n",
       " (16, 3): 0.04868035190615835,\n",
       " (32, 3): 0.04574780058651026,\n",
       " (64, 3): 0.052785923753665684,\n",
       " (128, 3): 0.047507331378299114,\n",
       " (256, 3): 0.04105571847507332,\n",
       " (512, 3): 0.03284457478005865,\n",
       " (1024, 3): 0.01818181818181818,\n",
       " (2048, 3): 0.004105571847507331,\n",
       " (16, 4): 0.04281524926686217,\n",
       " (32, 4): 0.04574780058651026,\n",
       " (64, 4): 0.04926686217008798,\n",
       " (128, 4): 0.0469208211143695,\n",
       " (256, 4): 0.0404692082111437,\n",
       " (512, 4): 0.03167155425219941,\n",
       " (1024, 4): 0.01935483870967742,\n",
       " (2048, 4): 0.004105571847507331}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd0e131",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5daa6e6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T11:49:43.617803Z",
     "start_time": "2023-03-15T11:49:43.604806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9f713d16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T12:11:53.455155Z",
     "start_time": "2023-03-15T12:11:53.369157Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 3\n",
    "\n",
    "# training\n",
    "vae_training = training[training['rating']>=alpha]\n",
    "n_users = vae_training['userid'].max()+1\n",
    "n_items = data_description['n_items']\n",
    "\n",
    "rows, cols = vae_training['userid'], vae_training['movieid']\n",
    "vae_train_data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                         (rows, cols)), dtype='float64',\n",
    "                         shape=(n_users, n_items))\n",
    "\n",
    "# validation\n",
    "start_idx = min(testset_valid['userid'].min(), holdout_valid['userid'].min())\n",
    "end_idx = max(testset_valid['userid'].max(), holdout_valid['userid'].max())\n",
    "\n",
    "rows_tr, cols_tr = testset_valid['userid'] - start_idx, testset_valid['movieid']\n",
    "rows_te, cols_te = holdout_valid['userid'] - start_idx, holdout_valid['movieid']\n",
    "\n",
    "valid_in_data = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                         (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "valid_out_data = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                         (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "\n",
    "# test\n",
    "start_idx = min(testset['userid'].min(), holdout['userid'].min())\n",
    "end_idx = max(testset['userid'].max(), holdout['userid'].max())\n",
    "\n",
    "rows_tr, cols_tr = testset['userid'] - start_idx, testset['movieid']\n",
    "rows_te, cols_te = holdout['userid'] - start_idx, holdout['movieid']\n",
    "\n",
    "test_in_data = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                         (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "test_out_data = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                         (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4f7a7c0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T12:13:54.042391Z",
     "start_time": "2023-03-15T12:13:53.877393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462784.0, 196310.0, 1705.0, 198048.0, 1738.0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(vae_train_data.A), np.sum(valid_in_data.A), np.sum(valid_out_data.A), np.sum(test_in_data.A), np.sum(test_out_data.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0234c39e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T12:20:53.338110Z",
     "start_time": "2023-03-15T12:20:53.319110Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def generate(batch_size, device, data_in, data_out=None, shuffle=False, samples_perc_per_epoch=1):\n",
    "    assert 0 < samples_perc_per_epoch <= 1\n",
    "    \n",
    "    total_samples = data_in.shape[0]\n",
    "    samples_per_epoch = int(total_samples * samples_perc_per_epoch)\n",
    "    \n",
    "    if shuffle:\n",
    "        idxlist = np.arange(total_samples)\n",
    "        np.random.shuffle(idxlist)\n",
    "        idxlist = idxlist[:samples_per_epoch]\n",
    "    else:\n",
    "        idxlist = np.arange(samples_per_epoch)\n",
    "    \n",
    "    for st_idx in range(0, samples_per_epoch, batch_size):\n",
    "        end_idx = min(st_idx + batch_size, samples_per_epoch)\n",
    "        idx = idxlist[st_idx:end_idx]\n",
    "\n",
    "        yield Batch(device, idx, data_in, data_out)\n",
    "\n",
    "\n",
    "class Batch:\n",
    "    def __init__(self, device, idx, data_in, data_out=None):\n",
    "        self._device = device\n",
    "        self._idx = idx\n",
    "        self._data_in = data_in\n",
    "        self._data_out = data_out\n",
    "    \n",
    "    def get_idx(self):\n",
    "        return self._idx\n",
    "    \n",
    "    def get_idx_to_dev(self):\n",
    "        return torch.LongTensor(self.get_idx()).to(self._device)\n",
    "        \n",
    "    def get_ratings(self, is_out=False):\n",
    "        data = self._data_out if is_out else self._data_in\n",
    "        return data[self._idx]\n",
    "    \n",
    "    def get_ratings_to_dev(self, is_out=False):\n",
    "        return torch.Tensor(\n",
    "            self.get_ratings(is_out).toarray()\n",
    "        ).to(self._device)\n",
    "\n",
    "\n",
    "def evaluate(model, data_in, data_out, metrics, samples_perc_per_epoch=1, batch_size=500):\n",
    "    metrics = deepcopy(metrics)\n",
    "    model.eval()\n",
    "    \n",
    "    for m in metrics:\n",
    "        m['score'] = []\n",
    "    \n",
    "    for batch in generate(batch_size=batch_size,\n",
    "                          device=device,\n",
    "                          data_in=data_in,\n",
    "                          data_out=data_out,\n",
    "                          samples_perc_per_epoch=samples_perc_per_epoch\n",
    "                         ):\n",
    "        ratings_in = batch.get_ratings_to_dev()\n",
    "#         print(ratings_in)\n",
    "        ratings_out = batch.get_ratings(is_out=True)\n",
    "#         print(ratings_out)\n",
    "    \n",
    "        ratings_pred = model(ratings_in, calculate_loss=False).cpu().detach().numpy()\n",
    "#         print(ratings_pred)\n",
    "        \n",
    "        if not (data_in is data_out):\n",
    "            ratings_pred[batch.get_ratings().nonzero()] = -np.inf\n",
    "            \n",
    "        for m in metrics:\n",
    "            m['score'].append(m['metric'](ratings_pred, ratings_out, k=m['k']))\n",
    "\n",
    "    for m in metrics:\n",
    "        m['score'] = np.concatenate(m['score']).mean()\n",
    "        \n",
    "    return [x['score'] for x in metrics]\n",
    "\n",
    "\n",
    "def run(model, opts, train_data, batch_size, n_epochs, beta, gamma, dropout_rate):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in generate(batch_size=batch_size, device=device, data_in=train_data, shuffle=True):\n",
    "            ratings = batch.get_ratings_to_dev()\n",
    "#             print(ratings)\n",
    "\n",
    "            for optimizer in opts:\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            a, loss = model(ratings, beta=beta, gamma=gamma, dropout_rate=dropout_rate)\n",
    "            print(a, loss)\n",
    "#             print(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            for optimizer in opts:\n",
    "                optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1d2851b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T12:20:53.837161Z",
     "start_time": "2023-03-15T12:20:53.827159Z"
    }
   },
   "outputs": [],
   "source": [
    "grid1 = np.arange(100, 2100, 100)\n",
    "grid = np.meshgrid(grid1, grid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8ad55305",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T12:20:56.255016Z",
     "start_time": "2023-03-15T12:20:54.074740Z"
    },
    "code_folding": [
     0,
     20,
     43
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liza\\Desktop\\Thesis\\RecVAE\\utils.py:98: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return DCG / IDCG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | valid ndcg@100: nan | best valid: -inf | train ndcg@100: 0.0184\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "(tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>), tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)) tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27924\\2651340918.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer_encoder\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlearning_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer_decoder\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlearning_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27924\\3679679009.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(model, opts, train_data, batch_size, n_epochs, beta, gamma, dropout_rate)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'differentiable'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             adam(params_with_grad,\n\u001b[0m\u001b[0;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m     func(params,\n\u001b[0m\u001b[0;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_kwargs = {\n",
    "    'hidden_dim': 100,\n",
    "    'latent_dim': 100,\n",
    "    'input_dim': vae_train_data.shape[1]\n",
    "}\n",
    "metrics = [{'metric': ndcg, 'k': 10}]\n",
    "\n",
    "best_ndcg = -np.inf\n",
    "train_scores, valid_scores = [], []\n",
    "\n",
    "model = RecVAE(**model_kwargs).to(device)\n",
    "model_best = RecVAE(**model_kwargs).to(device)\n",
    "\n",
    "learning_kwargs = {\n",
    "    'model': model,\n",
    "    'train_data': vae_train_data,\n",
    "    'batch_size': 512,\n",
    "    'beta': None,\n",
    "    'gamma': 0.005\n",
    "}\n",
    "\n",
    "decoder_params = set(model.decoder.parameters())\n",
    "encoder_params = set(model.encoder.parameters())\n",
    "\n",
    "optimizer_encoder = optim.Adam(encoder_params, lr=5e-4)\n",
    "optimizer_decoder = optim.Adam(decoder_params, lr=5e-4)\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    run(opts=[optimizer_encoder], n_epochs=3, dropout_rate=0.5, **learning_kwargs)\n",
    "    model.update_prior()\n",
    "    run(opts=[optimizer_decoder], n_epochs=1, dropout_rate=0, **learning_kwargs)\n",
    "\n",
    "    train_scores.append(\n",
    "        evaluate(model, vae_train_data, vae_train_data, metrics, 0.01)[0]\n",
    "    )\n",
    "    valid_scores.append(\n",
    "        evaluate(model, valid_in_data, valid_out_data, metrics, 1)[0]\n",
    "    )\n",
    "    \n",
    "    if valid_scores[-1] > best_ndcg:\n",
    "        best_ndcg = valid_scores[-1]\n",
    "        model_best.load_state_dict(deepcopy(model.state_dict()))\n",
    "        \n",
    "\n",
    "    print(f'epoch {epoch} | valid ndcg@100: {valid_scores[-1]:.4f} | ' +\n",
    "          f'best valid: {best_ndcg:.4f} | train ndcg@100: {train_scores[-1]:.4f}')\n",
    "\n",
    "\n",
    "    \n",
    "test_metrics = [{'metric': ndcg, 'k': 100}, {'metric': recall, 'k': 20}, {'metric': recall, 'k': 50}]\n",
    "\n",
    "final_scores = evaluate(model_best, test_in_data, test_out_data, test_metrics)\n",
    "\n",
    "for metric, score in zip(test_metrics, final_scores):\n",
    "    print(f\"{metric['metric'].__name__}@{metric['k']}:\\t{score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3e0fe046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T12:15:15.675502Z",
     "start_time": "2023-03-15T12:15:15.663497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91b5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "histories = []\n",
    "test_losses = []\n",
    "mrrs = []\n",
    "hrs = []\n",
    "cs = []\n",
    "\n",
    "\n",
    "for h1, h2, in tqdm(zip(grid[0].flatten(), grid[1].flatten()), total=24):\n",
    "    print('Hidden sizes:', h1, h2)\n",
    "    \n",
    "    vae = VAE(data_description['n_items'], data_description['n_ratings'], h1, h2).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "    optimizer = optim.Adam(ae.parameters(), lr=5*1e-4)\n",
    "    \n",
    "    mask = torch.triu(torch.ones_like(ae.L.weight))\n",
    "    # Register with hook\n",
    "    ae.L.weight.register_hook(get_zero_grad_hook(mask))\n",
    "    \n",
    "    params.append(sum(p.numel() for p in ae.parameters() if p.requires_grad))\n",
    "    \n",
    "    # Training the AE\n",
    "    n_epochs = 20\n",
    "    history = []\n",
    "    prev_train_loss = 1\n",
    "    train_loss = 0.1 * len(train_dataloader)\n",
    "    epoch = 1\n",
    "\n",
    "    while prev_train_loss - train_loss / len(train_dataloader) > 1e-4 or train_loss / len(train_dataloader) > 1e-2:\n",
    "        if epoch > 1:\n",
    "            prev_train_loss = train_loss / len(train_dataloader)\n",
    "        \n",
    "        train_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            user_tensor, user_matrix = batch\n",
    "\n",
    "            input_tensor = user_tensor.to_dense().to(device)\n",
    "            target = user_matrix.to_dense().to(device)\n",
    "\n",
    "            output = ae(input_tensor)\n",
    "            target.require_grad = False # we don't use it in training\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.data.item()\n",
    "\n",
    "        history.append(train_loss / len(train_dataloader))\n",
    "        epoch += 1\n",
    "        \n",
    "        if epoch > 50:\n",
    "            break\n",
    "    \n",
    "    histories.append(history)\n",
    "    \n",
    "#         print('epoch: '+str(epoch)+' loss: '+str(train_loss / len(train_dataloader)))\n",
    "    \n",
    "    # Testing the AE\n",
    "    test_loss = 0\n",
    "\n",
    "    for user in testset_valid.userid.unique():\n",
    "        itemidx = testset_valid.loc[testset_valid.userid == user, data_description['items']].values\n",
    "        feedbackidx = testset_valid.loc[testset_valid.userid == user, data_description['feedback']].values\n",
    "        values = np.ones(len(itemidx), dtype=np.float32)\n",
    "\n",
    "        user_tensor_test = torch.sparse_coo_tensor(np.array([itemidx, feedbackidx-1]), torch.tensor(values),\n",
    "                                  size=torch.Size((data_description[\"n_items\"], data_description['n_ratings']))).to_dense().to(device).unsqueeze(0)\n",
    "        target = torch.sparse_coo_tensor(np.array([itemidx]), torch.tensor(values),\n",
    "                                  size=torch.Size((data_description[\"n_items\"], ))).to_dense().to(device).unsqueeze(0)\n",
    "\n",
    "        output = ae(user_tensor_test)\n",
    "        target.require_grad = False\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.data.item()\n",
    "    \n",
    "    test_losses.append(test_loss / testset_valid.userid.nunique())\n",
    "\n",
    "#     print('test loss: '+str(test_loss / testset.userid.nunique()))\n",
    "    \n",
    "    scores = torch.zeros((len(testset_valid.userid.unique()), data_description['n_items']))\n",
    "    for i, user in enumerate(testset_valid.userid.unique()):\n",
    "        itemidx = testset_valid.loc[testset_valid.userid == user, data_description['items']].values\n",
    "        feedbackidx = testset_valid.loc[testset_valid.userid == user, data_description['feedback']].values\n",
    "        values = np.ones(len(itemidx), dtype=np.float32)\n",
    "\n",
    "        user_matrix_test = torch.sparse_coo_tensor(np.array([itemidx, feedbackidx-1]), torch.tensor(values),\n",
    "                                  size=torch.Size((data_description[\"n_items\"], data_description['n_ratings']))).to_dense().unsqueeze(0).to(device)\n",
    "\n",
    "        output = ae(user_matrix_test)\n",
    "        scores[i] = output[0].T\n",
    "\n",
    "\n",
    "    scores = scores.detach().numpy()\n",
    "    \n",
    "    # our\n",
    "    plt.plot(history)\n",
    "    plt.show()\n",
    "    print('Test loss:', test_loss / testset_valid.userid.nunique())\n",
    "    print('Epochs:', epoch)\n",
    "    downvote_seen_items(scores, testset_valid, data_description)\n",
    "    mrr10, hr10, c10 = make_prediction(scores, holdout_valid, data_description)\n",
    "    mrrs.append(mrr10)\n",
    "    hrs.append(hr10)\n",
    "    cs.append(c10)\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4225c29",
   "metadata": {},
   "source": [
    "# Test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd2765cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T11:46:51.897882Z",
     "start_time": "2023-03-18T11:46:51.871884Z"
    }
   },
   "outputs": [],
   "source": [
    "data_description = dict(\n",
    "    users = data_index['users'].name,\n",
    "    items = data_index['items'].name,\n",
    "    feedback = 'rating',\n",
    "    n_users = len(data_index['users']),\n",
    "    n_items = len(data_index['items']),\n",
    "    n_ratings = training['rating'].nunique(),\n",
    "    min_rating = training['rating'].min(),\n",
    "    test_users = holdout[data_index['users'].name].drop_duplicates().values,\n",
    "    n_test_users = holdout[data_index['users'].name].nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d1782a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T11:46:52.276570Z",
     "start_time": "2023-03-18T11:46:52.252566Z"
    }
   },
   "outputs": [],
   "source": [
    "train_val = pd.concat((training, testset_valid, holdout_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d4fa8d",
   "metadata": {},
   "source": [
    "## TopPop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1fa0baa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T11:46:53.232081Z",
     "start_time": "2023-03-18T11:46:53.156077Z"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 28.3 GiB for an array with shape (64282, 59065) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20816\\163271985.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpop_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_popularity_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_description\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpop_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpopularity_model_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_description\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdownvote_seen_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_description\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mholdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_description\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20816\\3618722839.py\u001b[0m in \u001b[0;36mpopularity_model_scoring\u001b[1;34m(params, testset, testset_description)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpopularity_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem_popularity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_popularity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# same scores for each test user\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopularity_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_users\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_users\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mtile\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mtile\u001b[1;34m(A, reps)\u001b[0m\n\u001b[0;32m   1256\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdim_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnrep\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m                 \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1259\u001b[0m             \u001b[0mn\u001b[0m \u001b[1;33m//=\u001b[0m \u001b[0mdim_in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 28.3 GiB for an array with shape (64282, 59065) and data type float64"
     ]
    }
   ],
   "source": [
    "pop_params = build_popularity_model(train_val, data_description)\n",
    "pop_scores = popularity_model_scoring(pop_params, None, data_description)\n",
    "downvote_seen_items(pop_scores, testset, data_description)\n",
    "\n",
    "make_prediction(pop_scores, holdout, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4540c869",
   "metadata": {},
   "source": [
    "## Normalized PureSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87640b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_params = build_svd_model({'rank':64, 'f':1.9}, training, data_description)\n",
    "svd_scores = svd_model_scoring(svd_params, testset, data_description)\n",
    "downvote_seen_items(svd_scores, testset, data_description)\n",
    "\n",
    "make_prediction(svd_scores, holdout, data_description, mode=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cca70d",
   "metadata": {},
   "source": [
    "## EASEr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88d230d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T11:17:40.558374Z",
     "start_time": "2023-03-18T11:17:37.544871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR@5</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>Coverage@5</th>\n",
       "      <th>HR_pos@5</th>\n",
       "      <th>HR_neg@5</th>\n",
       "      <th>MRR_pos@5</th>\n",
       "      <th>MRR_neg@5</th>\n",
       "      <th>Matthews@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.042002</td>\n",
       "      <td>0.021538</td>\n",
       "      <td>0.296797</td>\n",
       "      <td>0.039125</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.019476</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.060573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HR@5     MRR@5  Coverage@5  HR_pos@5  HR_neg@5  MRR_pos@5  MRR_neg@5  \\\n",
       "5  0.042002  0.021538    0.296797  0.039125  0.002877   0.019476   0.002062   \n",
       "\n",
       "   Matthews@5  \n",
       "5    0.060573  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR@10</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>Coverage@10</th>\n",
       "      <th>HR_pos@10</th>\n",
       "      <th>HR_neg@10</th>\n",
       "      <th>MRR_pos@10</th>\n",
       "      <th>MRR_neg@10</th>\n",
       "      <th>Matthews@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.066168</td>\n",
       "      <td>0.024755</td>\n",
       "      <td>0.420217</td>\n",
       "      <td>0.059839</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.022236</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.058168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HR@10    MRR@10  Coverage@10  HR_pos@10  HR_neg@10  MRR_pos@10  \\\n",
       "10  0.066168  0.024755     0.420217   0.059839   0.006329    0.022236   \n",
       "\n",
       "    MRR_neg@10  Matthews@10  \n",
       "10    0.002519     0.058168  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR@20</th>\n",
       "      <th>MRR@20</th>\n",
       "      <th>Coverage@20</th>\n",
       "      <th>HR_pos@20</th>\n",
       "      <th>HR_neg@20</th>\n",
       "      <th>MRR_pos@20</th>\n",
       "      <th>MRR_neg@20</th>\n",
       "      <th>Matthews@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.102417</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.559506</td>\n",
       "      <td>0.093786</td>\n",
       "      <td>0.008631</td>\n",
       "      <td>0.024614</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.083832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HR@20   MRR@20  Coverage@20  HR_pos@20  HR_neg@20  MRR_pos@20  \\\n",
       "20  0.102417  0.02729     0.559506   0.093786   0.008631    0.024614   \n",
       "\n",
       "    MRR_neg@20  Matthews@20  \n",
       "20    0.002676     0.083832  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.024755009406908147, 0.0661680092059839, 0.05816752651222287)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easer_params = easer(train_val, data_description, lmbda=260)\n",
    "easer_scores = easer_scoring(easer_params, testset, data_description)\n",
    "downvote_seen_items(easer_scores, testset, data_description)\n",
    "\n",
    "make_prediction(easer_scores, holdout, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7822366d",
   "metadata": {},
   "source": [
    "## CoFFee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc6dd0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-15T07:54:42.202Z"
    }
   },
   "outputs": [],
   "source": [
    "config['mlrank'] = (256, 256, 2)\n",
    "tf_params = tf_model_build(config, train_val, data_description)\n",
    "seen_data = testset\n",
    "tf_scores = tf_scoring(tf_params, seen_data, data_description)\n",
    "downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "cur_mrr, cur_hr, cur_C = make_prediction(tf_scores, holdout, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1277bc9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.306px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "195.847px",
    "left": "1336.67px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
