{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79e0fd30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:14:14.806160Z",
     "start_time": "2023-05-24T18:14:14.796160Z"
    }
   },
   "outputs": [],
   "source": [
    "from RecVAE.model import VAE\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from dataprep import full_preproccessing\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2b30823",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:13:18.569464Z",
     "start_time": "2023-05-24T18:13:18.291464Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ml-1m.csv')\n",
    "data.rename(columns = {'userId' : 'userid', 'movieId' : 'movieid'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0baecc69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:13:19.310119Z",
     "start_time": "2023-05-24T18:13:18.587464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6040 users\n",
      "Filtered 93 invalid observations.\n"
     ]
    }
   ],
   "source": [
    "training, testset_valid, holdout_valid, testset, holdout, data_description, data_index = full_preproccessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ce9296f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:15:09.571069Z",
     "start_time": "2023-05-24T18:15:09.558052Z"
    }
   },
   "outputs": [],
   "source": [
    "# answer = binary matrix (no ratings)\n",
    "class MVDataset(Dataset):\n",
    "    def __init__(self, data, data_description):\n",
    "        useridx = data[data_description['users']].values\n",
    "        itemidx = data[data_description['items']].values\n",
    "        feedbackidx = data[data_description['feedback']].values\n",
    "        values = np.ones(len(itemidx), dtype=np.float32)\n",
    "        \n",
    "#         self.tensor = torch.sparse_coo_tensor(np.array([useridx, itemidx, feedbackidx-1]), torch.tensor(values),\n",
    "#                                             size=torch.Size((data_description[\"n_users\"], data_description[\"n_items\"], data_description['n_ratings'])))\n",
    "        self.matrix = torch.sparse_coo_tensor(np.array([useridx, itemidx]), torch.tensor(values),\n",
    "                                      size=torch.Size((data_description[\"n_users\"], data_description[\"n_items\"])), dtype=torch.float32)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.matrix.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.matrix[idx], self.matrix[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8c4ed53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:15:09.858892Z",
     "start_time": "2023-05-24T18:15:09.843885Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = MVDataset(training, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1ad2f7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:22:55.244691Z",
     "start_time": "2023-05-24T18:22:55.225665Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "120105fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:22:56.414092Z",
     "start_time": "2023-05-24T18:22:56.363115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3403])\n",
      "torch.Size([16, 3403])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4218a70a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:22:57.936208Z",
     "start_time": "2023-05-24T18:22:57.913951Z"
    }
   },
   "outputs": [],
   "source": [
    "model = VAE(200, 100, data_description['n_items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bed07d2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:27:09.620986Z",
     "start_time": "2023-05-24T18:27:09.596989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3403])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch[0].to_dense(), calculate_loss=False, beta=0.5, gamma=0.005, dropout_rate=0.5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28edf9fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:26:36.271938Z",
     "start_time": "2023-05-24T18:26:36.253935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c37e6ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-25T17:45:46.598809Z",
     "start_time": "2023-05-25T17:43:56.967437Z"
    },
    "code_folding": [
     9,
     16,
     62
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6040 users\n",
      "Filtered 93 invalid observations.\n",
      "device: cuda:0\n",
      "Batch size: 500\n",
      "Hidden sizes: (16, 16, 0.005)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\GitHub\\Thesis_2023\\utils.py:68: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  C = (TP/N - S*P) / np.sqrt(P*S*(1-P)*(1-S))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22740\\1130657002.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msizes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Batch size:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     tuning_pipeline_augment(training, testset_valid, holdout_valid, data_description, recvae,\n\u001b[0m\u001b[0;32m     87\u001b[0m                             device, grid, MVDataset, batch_size=int(batch_size), tensor_model=False)\n",
      "\u001b[1;32mD:\\GitHub\\Thesis_2023\\utils.py\u001b[0m in \u001b[0;36mtuning_pipeline_augment\u001b[1;34m(training, testset_valid, holdout_valid, data_description, model_init, device, grid, MVDataset, batch_size, early_stop, n_epochs, tensor_model)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    632\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22740\\1130657002.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mnum_noise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0midxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_noise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0mnoised_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mnoised_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from RecVAE.model import VAE\n",
    "\n",
    "from dataprep import full_preproccessing\n",
    "from utils import *\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "# %%\n",
    "# answer = binary matrix (no ratings)\n",
    "class MVDataset(Dataset):\n",
    "    def __init__(self, data, data_description, augment=False):\n",
    "        self.augment = augment\n",
    "        useridx = data[data_description['users']].values\n",
    "        itemidx = data[data_description['items']].values\n",
    "        values = np.ones(len(itemidx), dtype=np.float32)\n",
    "        self.n_items = data_description['n_items']\n",
    "\n",
    "        self.matrix = torch.sparse_coo_tensor(np.array([useridx, itemidx]), torch.tensor(values),\n",
    "                                              size=torch.Size(\n",
    "                                                  (data_description[\"n_users\"], data_description[\"n_items\"])),\n",
    "                                              dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.matrix.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.augment:\n",
    "            num_noise = np.random.randint(0, int(0.1*self.matrix.shape[1]))\n",
    "            idxs = torch.randint(0, self.matrix.shape[1], size=(num_noise,))\n",
    "            noised_input = self.matrix[idx].detach().clone().to_dense()\n",
    "            noised_input[idxs] = 0\n",
    "\n",
    "            # useridx = np.zeros_like(noised_input.cpu())\n",
    "            itemidx = np.arange(self.matrix.shape[1])\n",
    "            noised_input = torch.sparse_coo_tensor(np.array([itemidx,]), noised_input,\n",
    "                                                size=torch.Size((self.n_items,)), dtype=torch.float32)\n",
    "            return noised_input, self.matrix[idx]\n",
    "        else:\n",
    "            return self.matrix[idx], self.matrix[idx]\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "\n",
    "\n",
    "set_random_seed(42)\n",
    "data = pd.read_csv('ml-1m.csv')\n",
    "data.rename(columns = {'userId' : 'userid', 'movieId' : 'movieid'}, inplace = True)\n",
    "\n",
    "# %%\n",
    "training, testset_valid, holdout_valid, testset, holdout, data_description, data_index = full_preproccessing(data)\n",
    "# %%\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n",
    "# %% [markdown]\n",
    "\n",
    "def recvae(h, data_description, device):\n",
    "    h1, h2, gamma = h\n",
    "    ae = VAE(h1, h2, data_description['n_items']).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "    optimizer = optim.Adam(ae.parameters(), lr=5*10e-4)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "    return ae, criterion, optimizer, scheduler\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Tuning\n",
    "\n",
    "# %%\n",
    "grid1 = 2 ** np.arange(4, 11)\n",
    "grid2 = 2 ** np.arange(4, 11)\n",
    "gamma = 0.001 * np.arange(5, 101, 5)\n",
    "grid = np.meshgrid(grid2, grid1, gamma)\n",
    "grid = list(zip(grid[0].flatten(), grid[1].flatten(), grid[2].flatten()))\n",
    "\n",
    "# %%\n",
    "sizes = [500]#2 ** np.arange(4, 10)\n",
    "for batch_size in sizes:\n",
    "    print('Batch size:', batch_size)\n",
    "    tuning_pipeline_augment(training, testset_valid, holdout_valid, data_description, recvae,\n",
    "                            device, grid, MVDataset, batch_size=int(batch_size), tensor_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f0ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
