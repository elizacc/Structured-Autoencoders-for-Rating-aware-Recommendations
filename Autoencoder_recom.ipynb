{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6b16d92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hwHmuC73aJy6",
    "outputId": "c4efbc70-d280-4581-a051-6d8664c3b17c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting polara\n",
      "  Cloning https://github.com/evfro/polara.git (to revision develop) to /tmp/pip-install-fswnmgch/polara_e9f7a3ee1aee4bef85936d915026c9aa\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/evfro/polara.git /tmp/pip-install-fswnmgch/polara_e9f7a3ee1aee4bef85936d915026c9aa\n",
      "  Running command git checkout -b develop --track origin/develop\n",
      "  Switched to a new branch 'develop'\n",
      "  Branch 'develop' set up to track remote branch 'develop' from 'origin'.\n",
      "  Resolved https://github.com/evfro/polara.git to commit 8e48cfd88e616ca53f8bbda1702a3e2c8abaf38e\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: polara\n",
      "  Building wheel for polara (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for polara: filename=polara-0.7.2.dev0-py3-none-any.whl size=89455 sha256=8b20b1b694ffcadfe37c708e9de299255a0563a323dd0f981bda6c033670c004\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-grqokw6s/wheels/d2/cf/bf/e1a3e49c4a733261d717fa4732eadf0303dabcc48ba694ad7a\n",
      "Successfully built polara\n",
      "Installing collected packages: polara\n",
      "Successfully installed polara-0.7.2.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --no-cache-dir --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "110ce224",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:15:00.787969Z",
     "start_time": "2023-04-20T10:15:00.769955Z"
    },
    "id": "f16cd3f8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.parametrizations import orthogonal\n",
    "from torch.nn import functional as F\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from dataprep import transform_indices, full_preproccessing\n",
    "from utils import topn_recommendations, downvote_seen_items, make_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f70e74dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T09:59:49.173799Z",
     "start_time": "2023-04-20T09:59:49.159798Z"
    },
    "id": "c41b93b3"
   },
   "outputs": [],
   "source": [
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65bf3ab1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T09:59:49.881869Z",
     "start_time": "2023-04-20T09:59:49.863876Z"
    },
    "code_folding": [
     0
    ],
    "id": "5e7c2f45"
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16a78e64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T09:59:50.602411Z",
     "start_time": "2023-04-20T09:59:50.579404Z"
    },
    "code_folding": [
     1
    ],
    "id": "6eaacb66"
   },
   "outputs": [],
   "source": [
    "# answer = binary matrix (no ratings)\n",
    "class MVDataset(Dataset):\n",
    "    def __init__(self, data, data_description, augment=False):\n",
    "        useridx = data[data_description['users']].values\n",
    "        itemidx = data[data_description['items']].values\n",
    "        feedbackidx = data[data_description['feedback']].values\n",
    "        values = np.ones(len(itemidx), dtype=np.float32)\n",
    "        \n",
    "        self.tensor = torch.sparse_coo_tensor(np.array([useridx, itemidx, feedbackidx-1]), torch.tensor(values),\n",
    "                                            size=torch.Size((data_description[\"n_users\"], data_description[\"n_items\"], data_description['n_ratings'])))\n",
    "        self.matrix = torch.sparse_coo_tensor(np.array([useridx, itemidx]), torch.tensor(values),\n",
    "                                      size=torch.Size((data_description[\"n_users\"], data_description[\"n_items\"])), dtype=torch.float32)\n",
    "        \n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensor.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.augment:\n",
    "            num_noise = np.random.randint(0, int(0.1*self.matrix.shape[1]))\n",
    "            idxs = torch.randint(0, self.matrix.shape[1], size=(num_noise,))\n",
    "            noised_input = self.tensor[idx].detach().clone().to_dense()\n",
    "            noised_input[idxs] = torch.distributions.bernoulli.Bernoulli(0.5).sample(sample_shape=(num_noise,))\n",
    "            \n",
    "            useridx = np.zeros_like(noised_input)\n",
    "            itemidx = np.arange(self.matrix.shape[1])\n",
    "            noised_input = torch.sparse_coo_tensor(np.array([itemidx,]), noised_input,\n",
    "                                                   size=torch.Size((data_description[\"n_items\"],)), dtype=torch.float32)\n",
    "            return noised_input, self.matrix[idx]\n",
    "        else:\n",
    "            return self.tensor[idx], self.matrix[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef9474b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T09:59:51.351744Z",
     "start_time": "2023-04-20T09:59:51.334669Z"
    },
    "code_folding": [
     0
    ],
    "id": "89fecf5a"
   },
   "outputs": [],
   "source": [
    "def prepare_tensor(data, data_description, tensor_model=True):\n",
    "    useridx = pd.factorize(data[data_description['users']])[0]\n",
    "    itemidx = data[data_description['items']].values\n",
    "    feedbackidx = data[data_description['feedback']].values\n",
    "    values = np.ones(len(itemidx), dtype=np.float32)\n",
    "    user_tensor_test = torch.sparse_coo_tensor(np.array([useridx, itemidx, feedbackidx-1]), torch.tensor(values),\n",
    "                                      size=torch.Size((data[data_description['users']].nunique(), data_description[\"n_items\"], data_description['n_ratings']))).to_dense().to(device)\n",
    "    target_test = torch.sparse_coo_tensor(np.array([useridx, itemidx]), torch.tensor(values),\n",
    "                                      size=torch.Size((data[data_description['users']].nunique(), data_description[\"n_items\"], ))).to_dense().to(device)\n",
    "    if tensor_model:\n",
    "        return user_tensor_test, target_test\n",
    "    else:\n",
    "        return target_test, target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e19784b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T09:59:52.243349Z",
     "start_time": "2023-04-20T09:59:52.225341Z"
    },
    "code_folding": [
     0
    ],
    "id": "3dc39622"
   },
   "outputs": [],
   "source": [
    "def predict_and_check(model, scores, holdout, data_description, hrs, mrrs, cs, ndcgs, alpha, prev_matt, epoch, h, disp=False, dcg=True):\n",
    "    mrr10, hr10, c10, ndcg10 = make_prediction(scores, holdout, data_description, disp=disp, dcg=dcg, alpha=alpha)\n",
    "    hrs.append(hr10)\n",
    "    mrrs.append(mrr10)\n",
    "    cs.append(c10)\n",
    "    ndcgs.append(ndcg10)\n",
    "\n",
    "    if np.max(prev_matt) < cs[-1] or epoch == 1:\n",
    "        prev_matt = [cs[-1]]\n",
    "        torch.save(model.state_dict(), f'best_ae_{h}_{alpha}.pt')\n",
    "#     elif prev_matt[-1] < cs[-1]:\n",
    "#         prev_matt = [cs[-1]]\n",
    "    else:\n",
    "        prev_matt.append(cs[-1])\n",
    "        \n",
    "    return prev_matt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a2c5d2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T09:59:52.826670Z",
     "start_time": "2023-04-20T09:59:52.810639Z"
    },
    "code_folding": [
     0
    ],
    "id": "62c735cd"
   },
   "outputs": [],
   "source": [
    "def check_test(model, criterion, user_tensor_test, target_test, testset, holdout, data_description, test_num_batches, alpha, h, batch_size=16, dcg=True):\n",
    "    test_loss = 0\n",
    "    scores = torch.zeros((len(testset.userid.unique()), data_description['n_items']))\n",
    "    \n",
    "    model.load_state_dict(torch.load(f'best_ae_{h}_{alpha}.pt'))\n",
    "    with torch.no_grad():\n",
    "        for batch in range(test_num_batches):\n",
    "            input_tensor = user_tensor_test[batch * batch_size: (batch+1) * batch_size].to(device)\n",
    "            target = target_test[batch * batch_size: (batch+1) * batch_size].to(device)\n",
    "\n",
    "            output = model(input_tensor)\n",
    "            target.require_grad = False\n",
    "\n",
    "            test_loss += criterion(output, target)\n",
    "            scores[batch * batch_size: (batch+1) * batch_size] = output\n",
    "\n",
    "    test_loss = test_loss / test_num_batches\n",
    "    scores = scores.detach().cpu().numpy()\n",
    "    downvote_seen_items(scores, testset, data_description)\n",
    "    print(f'Results for alpha={alpha}')\n",
    "    mrr10, hr10, c10, ndcg10 = make_prediction(scores, holdout, data_description, dcg=dcg, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0331950d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T09:59:53.395775Z",
     "start_time": "2023-04-20T09:59:53.364763Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def tuning_pipeline(training, testset_valid, holdout_valid, testset, holdout, data_description, model_init, device, grid, batch_size=16, tensor_model=True, early_stop=50, n_epochs=1000):\n",
    "    user_tensor_train, target_train = prepare_tensor(training, data_description, tensor_model)\n",
    "    user_tensor_val, target_val = prepare_tensor(testset_valid, data_description)\n",
    "    \n",
    "    num_batches = int(np.ceil(user_tensor_train.shape[0] / batch_size))\n",
    "    val_num_batches = int(np.ceil(target_val.shape[0] / batch_size))\n",
    "\n",
    "    for h in tqdm(grid):\n",
    "        print('Hidden sizes:', h)\n",
    "        \n",
    "        model, criterion, optimizer, scheduler = model_init(h, data_description, device)\n",
    "\n",
    "        # Training the AE\n",
    "        history = []\n",
    "        val_history = []\n",
    "\n",
    "        hrs2 = []\n",
    "        mrrs2 = []\n",
    "        cs2 = []\n",
    "        ndcgs2 = []\n",
    "\n",
    "        hrs3 = []\n",
    "        mrrs3 = []\n",
    "        cs3 = []\n",
    "        ndcgs3 = []\n",
    "\n",
    "        hrs4 = []\n",
    "        mrrs4 = []\n",
    "        cs4 = []\n",
    "        ndcgs4 = []\n",
    "\n",
    "        hrs5 = []\n",
    "        mrrs5 = []\n",
    "        cs5 = []\n",
    "        ndcgs5 = []\n",
    "\n",
    "        prev_matt2 = [0]\n",
    "        prev_matt3 = [0]\n",
    "        prev_matt4 = [0]\n",
    "        prev_matt5 = [0]\n",
    "\n",
    "        for epoch in range(1, n_epochs+1):\n",
    "            train_loss = 0\n",
    "            shuffle = np.random.choice(user_tensor_train.shape[0], size=user_tensor_train.shape[0], replace=False)\n",
    "            user_tensor_train = user_tensor_train[shuffle]\n",
    "\n",
    "            for batch in range(num_batches):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                input_tensor = user_tensor_train[batch * batch_size: (batch+1) * batch_size].to(device)\n",
    "                target = target_train[batch * batch_size: (batch+1) * batch_size].to(device)\n",
    "\n",
    "                output = model(input_tensor)\n",
    "                target.require_grad = False # we don't use it in training\n",
    "\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.data.item()\n",
    "\n",
    "            scheduler.step()\n",
    "            history.append(train_loss / num_batches)\n",
    "\n",
    "            test_loss = 0\n",
    "            scores = torch.zeros((testset_valid.userid.nunique(), data_description['n_items']))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for batch in range(val_num_batches):\n",
    "                    input_tensor = user_tensor_val[batch * batch_size: (batch+1) * batch_size].to(device)\n",
    "                    target = target_val[batch * batch_size: (batch+1) * batch_size].to(device)\n",
    "\n",
    "                    output = model(input_tensor)\n",
    "                    target.require_grad = False\n",
    "\n",
    "                    test_loss += criterion(output, target)\n",
    "                    scores[batch * batch_size: (batch+1) * batch_size] = output\n",
    "                model.train()\n",
    "\n",
    "            scores = scores.detach().cpu().numpy()\n",
    "            val_loss = test_loss / val_num_batches\n",
    "            val_history.append(val_loss.item())\n",
    "\n",
    "            downvote_seen_items(scores, testset_valid, data_description)\n",
    "\n",
    "            prev_matt2 = predict_and_check(model, scores, holdout_valid, data_description, hrs2, mrrs2, cs2, ndcgs2, 2, prev_matt2, epoch, h)\n",
    "            prev_matt3 = predict_and_check(model, scores, holdout_valid, data_description, hrs3, mrrs3, cs3, ndcgs3, 3, prev_matt3, epoch, h)\n",
    "            prev_matt4 = predict_and_check(model, scores, holdout_valid, data_description, hrs4, mrrs4, cs4, ndcgs4, 4, prev_matt4, epoch, h)\n",
    "            prev_matt5 = predict_and_check(model, scores, holdout_valid, data_description, hrs5, mrrs5, cs5, ndcgs5, 5, prev_matt5, epoch, h)\n",
    "\n",
    "            # stop = epoch if epoch < early_stop else epoch-early_stop\n",
    "            if len(prev_matt2) >= early_stop and len(prev_matt3) >= early_stop and len(prev_matt4) >= early_stop and len(prev_matt5) >= early_stop:\n",
    "                print(f'Current epoch {epoch}')\n",
    "                break\n",
    "\n",
    "        # Testing the AE\n",
    "        check_test(model, criterion, user_tensor_val, target_val, testset_valid, holdout_valid, data_description, val_num_batches, 2, h, batch_size=batch_size, dcg=True)\n",
    "        check_test(model, criterion, user_tensor_val, target_val, testset_valid, holdout_valid, data_description, val_num_batches, 3, h, batch_size=batch_size, dcg=True)\n",
    "        check_test(model, criterion, user_tensor_val, target_val, testset_valid, holdout_valid, data_description, val_num_batches, 4, h, batch_size=batch_size, dcg=True)\n",
    "        check_test(model, criterion, user_tensor_val, target_val, testset_valid, holdout_valid, data_description, val_num_batches, 5, h, batch_size=batch_size, dcg=True)\n",
    "\n",
    "        # our\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(history, label='train')\n",
    "        plt.plot(val_history, label='val')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        hrs = [hrs2, hrs3, hrs4, hrs5]\n",
    "        mrrs = [mrrs2, mrrs3, mrrs4, mrrs5]\n",
    "        cs = [cs2, cs3, cs4, cs5]\n",
    "        ndcgs = [ndcgs2, ndcgs3, ndcgs4, ndcgs5]\n",
    "\n",
    "        fig = plt.figure(figsize=(24,5))\n",
    "        axes = fig.subplots(nrows=1, ncols=4)\n",
    "        for i in range(4):\n",
    "            axes[i].set_title(f'alpha={i+2}')\n",
    "            axes[i].plot(hrs[i], label='HR@10')\n",
    "            axes[i].plot(mrrs[i], label='MRR@10')\n",
    "            axes[i].plot(cs[i], label='Matthews@10')\n",
    "            axes[i].plot(ndcgs[i], label='NDCG@10')\n",
    "            axes[i].legend()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        print('Test loss:', val_history[-min(early_stop, epoch)])\n",
    "        print('Train loss:', history[-min(early_stop, epoch)])\n",
    "\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec62352c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T09:59:53.942031Z",
     "start_time": "2023-04-20T09:59:53.914019Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def tuning_pipeline_augment(training, testset_valid, holdout_valid, testset, holdout, data_description, model_init, device, grid, batch_size=16, tensor_model=True, early_stop=50, n_epochs=1000):\n",
    "    train_dataset = MVDataset(training, data_description, augment=True)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    user_tensor_val, target_val = prepare_tensor(testset_valid, data_description)    \n",
    "    val_num_batches = int(np.ceil(target_val.shape[0] / batch_size))\n",
    "\n",
    "    for h in tqdm(grid):\n",
    "        print('Hidden sizes:', h)\n",
    "        \n",
    "        model, criterion, optimizer, scheduler = model_init(h, data_description, device)\n",
    "\n",
    "        # Training the AE\n",
    "        history = []\n",
    "        val_history = []\n",
    "\n",
    "        hrs2 = []\n",
    "        mrrs2 = []\n",
    "        cs2 = []\n",
    "        ndcgs2 = []\n",
    "\n",
    "        hrs3 = []\n",
    "        mrrs3 = []\n",
    "        cs3 = []\n",
    "        ndcgs3 = []\n",
    "\n",
    "        hrs4 = []\n",
    "        mrrs4 = []\n",
    "        cs4 = []\n",
    "        ndcgs4 = []\n",
    "\n",
    "        hrs5 = []\n",
    "        mrrs5 = []\n",
    "        cs5 = []\n",
    "        ndcgs5 = []\n",
    "\n",
    "        prev_matt2 = [0]\n",
    "        prev_matt3 = [0]\n",
    "        prev_matt4 = [0]\n",
    "        prev_matt5 = [0]\n",
    "\n",
    "        for epoch in range(1, n_epochs+1):\n",
    "            train_loss = 0\n",
    "            shuffle = np.random.choice(user_tensor_train.shape[0], size=user_tensor_train.shape[0], replace=False)\n",
    "            user_tensor_train = user_tensor_train[shuffle]\n",
    "\n",
    "            for batch in train_dataloader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                input_tensor, target = batch\n",
    "                input_tensor, target = input_tensor.to_dense().to(device), target.to_dense().to(device)\n",
    "\n",
    "                output = model(input_tensor)\n",
    "                target.require_grad = False # we don't use it in training\n",
    "\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.data.item()\n",
    "\n",
    "            scheduler.step()\n",
    "            history.append(train_loss / len(train_dataloader))\n",
    "\n",
    "            test_loss = 0\n",
    "            scores = torch.zeros((testset_valid.userid.nunique(), data_description['n_items']))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for batch in range(val_num_batches):\n",
    "                    input_tensor = user_tensor_val[batch * batch_size: (batch+1) * batch_size].to(device)\n",
    "                    target = target_val[batch * batch_size: (batch+1) * batch_size].to(device)\n",
    "\n",
    "                    output = model(input_tensor)\n",
    "                    target.require_grad = False\n",
    "\n",
    "                    test_loss += criterion(output, target)\n",
    "                    scores[batch * batch_size: (batch+1) * batch_size] = output\n",
    "                model.train()\n",
    "\n",
    "            scores = scores.detach().cpu().numpy()\n",
    "            val_loss = test_loss / val_num_batches\n",
    "            val_history.append(val_loss.item())\n",
    "\n",
    "            downvote_seen_items(scores, testset_valid, data_description)\n",
    "\n",
    "            prev_matt2 = predict_and_check(model, scores, holdout_valid, data_description, hrs2, mrrs2, cs2, ndcgs2, 2, prev_matt2, epoch)\n",
    "            prev_matt3 = predict_and_check(model, scores, holdout_valid, data_description, hrs3, mrrs3, cs3, ndcgs3, 3, prev_matt3, epoch)\n",
    "            prev_matt4 = predict_and_check(model, scores, holdout_valid, data_description, hrs4, mrrs4, cs4, ndcgs4, 4, prev_matt4, epoch)\n",
    "            prev_matt5 = predict_and_check(model, scores, holdout_valid, data_description, hrs5, mrrs5, cs5, ndcgs5, 5, prev_matt5, epoch)\n",
    "\n",
    "            # stop = epoch if epoch < early_stop else epoch-early_stop\n",
    "            if len(prev_matt2) >= early_stop and len(prev_matt3) >= early_stop and len(prev_matt4) >= early_stop and len(prev_matt5) >= early_stop:\n",
    "                print(f'Current epoch {epoch}')\n",
    "                break\n",
    "\n",
    "        # Testing the AE\n",
    "        check_test(model, criterion, user_tensor_val, target_test, testset_valid, holdout_valid, data_description, val_num_batches, 2, batch_size=batch_size, dcg=True)\n",
    "        check_test(model, criterion, user_tensor_val, target_test, testset_valid, holdout_valid, data_description, val_num_batches, 3, batch_size=batch_size, dcg=True)\n",
    "        check_test(model, criterion, user_tensor_val, target_test, testset_valid, holdout_valid, data_description, val_num_batches, 4, batch_size=batch_size, dcg=True)\n",
    "        check_test(model, criterion, user_tensor_val, target_test, testset_valid, holdout_valid, data_description, val_num_batches, 5, batch_size=batch_size, dcg=True)\n",
    "\n",
    "        # our\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(history, label='train')\n",
    "        plt.plot(val_history, label='val')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        hrs = [hrs2, hrs3, hrs4, hrs5]\n",
    "        mrrs = [mrrs2, mrrs3, mrrs4, mrrs5]\n",
    "        cs = [cs2, cs3, cs4, cs5]\n",
    "        ndcgs = [ndcgs2, ndcgs3, ndcgs4, ndcgs5]\n",
    "\n",
    "        fig = plt.figure(figsize=(24,5))\n",
    "        axes = fig.subplots(nrows=1, ncols=4)\n",
    "        for i in range(4):\n",
    "            axes[i].set_title(f'alpha={i+2}')\n",
    "            axes[i].plot(hrs[i], label='HR@10')\n",
    "            axes[i].plot(mrrs[i], label='MRR@10')\n",
    "            axes[i].plot(cs[i], label='Matthews@10')\n",
    "            axes[i].plot(ndcgs[i], label='NDCG@10')\n",
    "            axes[i].legend()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        print('Test loss:', val_history[-min(early_stop, epoch)])\n",
    "        print('Train loss:', history[-min(early_stop, epoch)])\n",
    "\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad21b9f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T09:59:54.430965Z",
     "start_time": "2023-04-20T09:59:54.412986Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def training_testing_pipeline(training, testset_valid, holdout_valid, testset, holdout, data_description, model_init, h, device, batch_size=16, tensor_model=True, early_stop=50, n_epochs=1000):\n",
    "    train_val = pd.concat((training, testset_valid, holdout_valid))\n",
    "    user_tensor_train, target_train = prepare_tensor(train_val, data_description, tensor_model)\n",
    "    user_tensor_val, target_val = prepare_tensor(testset, data_description)\n",
    "    \n",
    "    num_batches = int(np.ceil(user_tensor_train.shape[0] / batch_size))\n",
    "    val_num_batches = int(np.ceil(target_val.shape[0] / batch_size))\n",
    "\n",
    "    print('Hidden sizes:', h)\n",
    "\n",
    "    model, criterion, optimizer, scheduler = model_init(h, data_description, device)\n",
    "\n",
    "    # Training the AE\n",
    "    history = []\n",
    "    val_history = []\n",
    "\n",
    "    hrs2 = []\n",
    "    mrrs2 = []\n",
    "    cs2 = []\n",
    "    ndcgs2 = []\n",
    "\n",
    "    hrs3 = []\n",
    "    mrrs3 = []\n",
    "    cs3 = []\n",
    "    ndcgs3 = []\n",
    "\n",
    "    hrs4 = []\n",
    "    mrrs4 = []\n",
    "    cs4 = []\n",
    "    ndcgs4 = []\n",
    "\n",
    "    hrs5 = []\n",
    "    mrrs5 = []\n",
    "    cs5 = []\n",
    "    ndcgs5 = []\n",
    "\n",
    "    prev_matt2 = [0]\n",
    "    prev_matt3 = [0]\n",
    "    prev_matt4 = [0]\n",
    "    prev_matt5 = [0]\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = 0\n",
    "        shuffle = np.random.choice(user_tensor_train.shape[0], size=user_tensor_train.shape[0], replace=False)\n",
    "        user_tensor_train = user_tensor_train[shuffle]\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_tensor = user_tensor_train[batch * batch_size: (batch+1) * batch_size].to(device)\n",
    "            target = target_train[batch * batch_size: (batch+1) * batch_size].to(device)\n",
    "\n",
    "            output = model(input_tensor)\n",
    "            target.require_grad = False # we don't use it in training\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.data.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        history.append(train_loss / num_batches)\n",
    "\n",
    "        test_loss = 0\n",
    "        scores = torch.zeros((testset.userid.nunique(), data_description['n_items']))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in range(val_num_batches):\n",
    "                input_tensor = user_tensor_val[batch * batch_size: (batch+1) * batch_size].to(device)\n",
    "                target = target_val[batch * batch_size: (batch+1) * batch_size].to(device)\n",
    "\n",
    "                output = model(input_tensor)\n",
    "                target.require_grad = False\n",
    "\n",
    "                test_loss += criterion(output, target)\n",
    "                scores[batch * batch_size: (batch+1) * batch_size] = output\n",
    "            model.train()\n",
    "\n",
    "        scores = scores.detach().cpu().numpy()\n",
    "        val_loss = test_loss / val_num_batches\n",
    "        val_history.append(val_loss.item())\n",
    "\n",
    "        downvote_seen_items(scores, testset, data_description)\n",
    "\n",
    "        prev_matt2 = predict_and_check(model, scores, holdout, data_description, hrs2, mrrs2, cs2, ndcgs2, 2, prev_matt2, epoch)\n",
    "        prev_matt3 = predict_and_check(model, scores, holdout, data_description, hrs3, mrrs3, cs3, ndcgs3, 3, prev_matt3, epoch)\n",
    "        prev_matt4 = predict_and_check(model, scores, holdout, data_description, hrs4, mrrs4, cs4, ndcgs4, 4, prev_matt4, epoch)\n",
    "        prev_matt5 = predict_and_check(model, scores, holdout, data_description, hrs5, mrrs5, cs5, ndcgs5, 5, prev_matt5, epoch)\n",
    "\n",
    "        # stop = epoch if epoch < early_stop else epoch-early_stop\n",
    "        if len(prev_matt2) >= early_stop and len(prev_matt3) >= early_stop and len(prev_matt4) >= early_stop and len(prev_matt5) >= early_stop:\n",
    "            print(f'Current epoch {epoch}')\n",
    "            break\n",
    "\n",
    "    # Testing the AE\n",
    "    check_test(model, criterion, user_tensor_val, target_val, testset, holdout, data_description, val_num_batches, 2, batch_size=batch_size, dcg=True)\n",
    "    check_test(model, criterion, user_tensor_val, target_val, testset, holdout, data_description, val_num_batches, 3, batch_size=batch_size, dcg=True)\n",
    "    check_test(model, criterion, user_tensor_val, target_val, testset, holdout, data_description, val_num_batches, 4, batch_size=batch_size, dcg=True)\n",
    "    check_test(model, criterion, user_tensor_val, target_val, testset, holdout, data_description, val_num_batches, 5, batch_size=batch_size, dcg=True)\n",
    "\n",
    "    # our\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history, label='train')\n",
    "    plt.plot(val_history, label='val')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    hrs = [hrs2, hrs3, hrs4, hrs5]\n",
    "    mrrs = [mrrs2, mrrs3, mrrs4, mrrs5]\n",
    "    cs = [cs2, cs3, cs4, cs5]\n",
    "    ndcgs = [ndcgs2, ndcgs3, ndcgs4, ndcgs5]\n",
    "\n",
    "    fig = plt.figure(figsize=(24,5))\n",
    "    axes = fig.subplots(nrows=1, ncols=4)\n",
    "    for i in range(4):\n",
    "        axes[i].set_title(f'alpha={i+2}')\n",
    "        axes[i].plot(hrs[i], label='HR@10')\n",
    "        axes[i].plot(mrrs[i], label='MRR@10')\n",
    "        axes[i].plot(cs[i], label='Matthews@10')\n",
    "        axes[i].plot(ndcgs[i], label='NDCG@10')\n",
    "        axes[i].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print('Test loss:', val_history[-min(early_stop, epoch)])\n",
    "    print('Train loss:', history[-min(early_stop, epoch)])\n",
    "\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9499f5ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T09:59:54.963248Z",
     "start_time": "2023-04-20T09:59:54.930219Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def training_testing_pipeline_augment(training, testset_valid, holdout_valid, testset, holdout, data_description, model_init, h, device, batch_size=16, tensor_model=True, early_stop=50, n_epochs=1000):\n",
    "    train_val = pd.concat((training, testset_valid, holdout_valid))\n",
    "    train_dataset = MVDataset(train_val, data_description, augment=True)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    user_tensor_val, target_val = prepare_tensor(testset_valid, data_description)    \n",
    "    val_num_batches = int(np.ceil(target_val.shape[0] / batch_size))\n",
    "\n",
    "    print('Hidden sizes:', h)\n",
    "\n",
    "    model, criterion, optimizer, scheduler = model_init(h, data_description, device)\n",
    "\n",
    "    # Training the AE\n",
    "    history = []\n",
    "    val_history = []\n",
    "\n",
    "    hrs2 = []\n",
    "    mrrs2 = []\n",
    "    cs2 = []\n",
    "    ndcgs2 = []\n",
    "\n",
    "    hrs3 = []\n",
    "    mrrs3 = []\n",
    "    cs3 = []\n",
    "    ndcgs3 = []\n",
    "\n",
    "    hrs4 = []\n",
    "    mrrs4 = []\n",
    "    cs4 = []\n",
    "    ndcgs4 = []\n",
    "\n",
    "    hrs5 = []\n",
    "    mrrs5 = []\n",
    "    cs5 = []\n",
    "    ndcgs5 = []\n",
    "\n",
    "    prev_matt2 = [0]\n",
    "    prev_matt3 = [0]\n",
    "    prev_matt4 = [0]\n",
    "    prev_matt5 = [0]\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = 0\n",
    "        shuffle = np.random.choice(user_tensor_train.shape[0], size=user_tensor_train.shape[0], replace=False)\n",
    "        user_tensor_train = user_tensor_train[shuffle]\n",
    "\n",
    "        for batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_tensor, target = batch\n",
    "            input_tensor, target = input_tensor.to_dense().to(device), target.to_dense().to(device)\n",
    "\n",
    "            output = model(input_tensor)\n",
    "            target.require_grad = False # we don't use it in training\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.data.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        history.append(train_loss / num_batches)\n",
    "\n",
    "        test_loss = 0\n",
    "        scores = torch.zeros((testset.userid.nunique(), data_description['n_items']))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in range(val_num_batches):\n",
    "                input_tensor = user_tensor_val[batch * batch_size: (batch+1) * batch_size].to(device)\n",
    "                target = target_val[batch * batch_size: (batch+1) * batch_size].to(device)\n",
    "\n",
    "                output = model(input_tensor)\n",
    "                target.require_grad = False\n",
    "\n",
    "                test_loss += criterion(output, target)\n",
    "                scores[batch * batch_size: (batch+1) * batch_size] = output\n",
    "            model.train()\n",
    "\n",
    "        scores = scores.detach().cpu().numpy()\n",
    "        val_loss = test_loss / val_num_batches\n",
    "        val_history.append(val_loss.item())\n",
    "\n",
    "        downvote_seen_items(scores, testset, data_description)\n",
    "\n",
    "        prev_matt2 = predict_and_check(model, scores, holdout, data_description, hrs2, mrrs2, cs2, ndcgs2, 2, prev_matt2, epoch)\n",
    "        prev_matt3 = predict_and_check(model, scores, holdout, data_description, hrs3, mrrs3, cs3, ndcgs3, 3, prev_matt3, epoch)\n",
    "        prev_matt4 = predict_and_check(model, scores, holdout, data_description, hrs4, mrrs4, cs4, ndcgs4, 4, prev_matt4, epoch)\n",
    "        prev_matt5 = predict_and_check(model, scores, holdout, data_description, hrs5, mrrs5, cs5, ndcgs5, 5, prev_matt5, epoch)\n",
    "\n",
    "        # stop = epoch if epoch < early_stop else epoch-early_stop\n",
    "        if len(prev_matt2) >= early_stop and len(prev_matt3) >= early_stop and len(prev_matt4) >= early_stop and len(prev_matt5) >= early_stop:\n",
    "            print(f'Current epoch {epoch}')\n",
    "            break\n",
    "\n",
    "    # Testing the AE\n",
    "    check_test(model, criterion, user_tensor_val, target_val, testset, holdout, data_description, val_num_batches, 2, batch_size=batch_size, dcg=True)\n",
    "    check_test(model, criterion, user_tensor_val, target_val, testset, holdout, data_description, val_num_batches, 3, batch_size=batch_size, dcg=True)\n",
    "    check_test(model, criterion, user_tensor_val, target_val, testset, holdout, data_description, val_num_batches, 4, batch_size=batch_size, dcg=True)\n",
    "    check_test(model, criterion, user_tensor_val, target_val, testset, holdout, data_description, val_num_batches, 5, batch_size=batch_size, dcg=True)\n",
    "\n",
    "    # our\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history, label='train')\n",
    "    plt.plot(val_history, label='val')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    hrs = [hrs2, hrs3, hrs4, hrs5]\n",
    "    mrrs = [mrrs2, mrrs3, mrrs4, mrrs5]\n",
    "    cs = [cs2, cs3, cs4, cs5]\n",
    "    ndcgs = [ndcgs2, ndcgs3, ndcgs4, ndcgs5]\n",
    "\n",
    "    fig = plt.figure(figsize=(24,5))\n",
    "    axes = fig.subplots(nrows=1, ncols=4)\n",
    "    for i in range(4):\n",
    "        axes[i].set_title(f'alpha={i+2}')\n",
    "        axes[i].plot(hrs[i], label='HR@10')\n",
    "        axes[i].plot(mrrs[i], label='MRR@10')\n",
    "        axes[i].plot(cs[i], label='Matthews@10')\n",
    "        axes[i].plot(ndcgs[i], label='NDCG@10')\n",
    "        axes[i].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print('Test loss:', val_history[-min(early_stop, epoch)])\n",
    "    print('Train loss:', history[-min(early_stop, epoch)])\n",
    "\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483ba188",
   "metadata": {
    "id": "2fd76395"
   },
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3729c038",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T09:59:56.368319Z",
     "start_time": "2023-04-20T09:59:56.231215Z"
    },
    "id": "910781c7"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Amazon_Video_Games.csv')\n",
    "data.rename(columns = {'reviewerID' : 'userid', 'asin' : 'movieid', \"overall\" : \"rating\", \"unixReviewTime\" : \"timestamp\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "400f82b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T09:59:57.574757Z",
     "start_time": "2023-04-20T09:59:56.900931Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5df9d793",
    "outputId": "f1e5230f-cd63-4ceb-b284-f7a52fd36570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24303 users\n",
      "Filtered 17693 invalid observations.\n"
     ]
    }
   ],
   "source": [
    "training, testset_valid, holdout_valid, testset, holdout, data_description, data_index = full_preproccessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd09e2e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T09:59:59.541734Z",
     "start_time": "2023-04-20T09:59:59.449313Z"
    },
    "id": "3ec8553c"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dceee71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:00:00.063727Z",
     "start_time": "2023-04-20T10:00:00.039413Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e62746e1",
    "outputId": "bfd2c702-699f-45d8-ee9a-046abc673647"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee559e4",
   "metadata": {
    "id": "5989fce5"
   },
   "source": [
    "## Model: triangular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02040b52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:00:01.435038Z",
     "start_time": "2023-04-20T10:00:01.427024Z"
    },
    "code_folding": [
     0,
     5
    ],
    "id": "c19dfcbf"
   },
   "outputs": [],
   "source": [
    "def triu_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        with torch.no_grad():\n",
    "            m.weight.copy_(torch.tril(m.weight))\n",
    "            \n",
    "def get_zero_grad_hook(mask):\n",
    "    def hook(grad):\n",
    "        return grad * mask\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7c3198c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:00:02.042623Z",
     "start_time": "2023-04-20T10:00:02.023619Z"
    },
    "code_folding": [],
    "id": "d667ffe2"
   },
   "outputs": [],
   "source": [
    "class triangularAE(nn.Module):\n",
    "    def __init__(self, n_items, n_ratings, hid1, hid2):\n",
    "        super(triangularAE, self).__init__()\n",
    "        self.V = nn.Linear(n_items, hid1, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(self.V.weight)\n",
    "        self.W = nn.Linear(n_ratings, hid2, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(self.W.weight)\n",
    "        self.L = nn.Linear(n_ratings, n_ratings, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(self.L.weight)\n",
    "        triu_init(self.L)\n",
    "#         self.norm = nn.LayerNorm(n_ratings)\n",
    "        self.vec = nn.Linear(n_ratings, 1)\n",
    "        torch.nn.init.xavier_uniform_(self.vec.weight)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        x = self.L(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.W(x)\n",
    "        x = self.relu(x)\n",
    "        xT = torch.transpose(x, -1, -2)\n",
    "        yT = self.V(xT)\n",
    "        y = torch.transpose(yT, -1, -2)\n",
    "        y = self.relu(y)\n",
    "        # decode\n",
    "        output = F.linear(y, self.W.weight.T)\n",
    "        output = self.relu(output)\n",
    "        outputT = torch.transpose(output, -1, -2)\n",
    "        outputT = torch.linalg.solve(self.L.weight, outputT)\n",
    "        outputT = self.relu(outputT)\n",
    "        outputT = F.linear(outputT, self.V.weight.T)\n",
    "        output = torch.transpose(outputT, -1, -2)\n",
    "        \n",
    "#         output = self.relu(output)\n",
    "        # vec\n",
    "        output = self.vec(output).squeeze(-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9202a961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:00:02.802039Z",
     "start_time": "2023-04-20T10:00:02.784067Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def triangular_model(h, data_description, device):\n",
    "    h1, h2 = h\n",
    "    ae = triangularAE(data_description['n_items'], data_description['n_ratings'], h1, h2).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "    optimizer = optim.Adam(ae.parameters())\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "    mask = torch.tril(torch.ones_like(ae.L.weight))\n",
    "    ae.L.weight.register_hook(get_zero_grad_hook(mask))\n",
    "    \n",
    "    return ae, criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf82dc",
   "metadata": {
    "id": "1c6c934d"
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b7586b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T17:45:34.598671Z",
     "start_time": "2023-04-19T17:45:34.590670Z"
    },
    "id": "5ac1568f"
   },
   "outputs": [],
   "source": [
    "grid1 = 2**np.arange(4, 11)\n",
    "grid2 = np.arange(3, 6)\n",
    "grid = np.meshgrid(grid2, grid1)\n",
    "grid = list(zip(grid[1].flatten(), grid[0].flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26280b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T17:45:44.755261Z",
     "start_time": "2023-04-19T17:45:35.364162Z"
    }
   },
   "outputs": [],
   "source": [
    "tuning_pipeline(training, testset_valid, holdout_valid, testset, holdout, data_description, triangular_model, device, grid, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68bac33",
   "metadata": {
    "id": "a1d4a4c2"
   },
   "source": [
    "## Model: triangular banded matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd24d6dc",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "cc767312"
   },
   "outputs": [],
   "source": [
    "class bandedLinear(nn.Module):\n",
    "    def __init__(self, num_features, bias: bool = True, device=None, dtype=None):\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        self.device = device\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.weight = nn.Parameter(torch.empty((num_features,1), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(num_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=np.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / np.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input):\n",
    "        M = torch.zeros((self.num_features, self.num_features), device=self.weight.device)\n",
    "        for i in range(self.num_features):\n",
    "            d = torch.ones(self.num_features-i, device=self.weight.device) * self.weight[i]\n",
    "            M = M + torch.diag(d, diagonal=-i)\n",
    "        return F.linear(input, M, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'num_features={}, bias={}'.format(\n",
    "            self.num_features, self.bias is not None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9182f50e",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "b71a80b1"
   },
   "outputs": [],
   "source": [
    "class triangularbandedAE(nn.Module):\n",
    "    def __init__(self, n_items, n_ratings, hid1, hid2):\n",
    "        super(AE, self).__init__()\n",
    "        self.V = nn.Linear(n_items, hid1)\n",
    "        torch.nn.init.xavier_uniform_(self.V.weight)\n",
    "        self.W = nn.Linear(n_ratings, hid2)\n",
    "        torch.nn.init.xavier_uniform_(self.W.weight)\n",
    "        self.L = bandedLinear(n_ratings, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(self.L.weight)\n",
    "        self.norm = nn.LayerNorm(n_ratings)\n",
    "        self.vec = nn.Linear(n_ratings, 1)\n",
    "        torch.nn.init.xavier_uniform_(self.vec.weight)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        M = torch.zeros((self.L.weight.shape[0], self.L.weight.shape[0]), device=self.L.weight.device)\n",
    "        for i in range(self.L.weight.shape[0]):\n",
    "            d = torch.ones(self.L.weight.shape[0]-i, device=self.L.weight.device) * self.L.weight[i]\n",
    "            M = M + torch.diag(d, diagonal=-i)\n",
    "        M.require_grad = True\n",
    "        \n",
    "        # encode\n",
    "        x = torch.matmul(x, M.T)\n",
    "        x = self.relu(x)\n",
    "        x = self.W(x)\n",
    "        x = self.relu(x)\n",
    "        xT = torch.transpose(x, -1, -2)\n",
    "        yT = self.V(xT)\n",
    "        y = torch.transpose(yT, -1, -2)\n",
    "        y = self.relu(y)\n",
    "        # decode\n",
    "        output = torch.matmul(y, self.W.weight) + self.W.bias\n",
    "        output = self.relu(output)\n",
    "        outputT = torch.transpose(output, -1, -2)\n",
    "        outputT = torch.linalg.solve(self.M.weight, outputT)\n",
    "        outputT = self.relu(outputT)\n",
    "        outputT = torch.matmul(outputT, self.V.weight.T) + self.V.bias\n",
    "        output = torch.transpose(outputT, -1, -2)\n",
    "        \n",
    "#         output = self.relu(output)\n",
    "        # vec\n",
    "        output = self.vec(output).squeeze(-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239c6d6b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def triangular_banded_model(h, data_description, device):\n",
    "    h1, h2 = h\n",
    "    ae = triangularbandedAE(data_description['n_items'], data_description['n_ratings'], h1, h2).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "    optimizer = optim.Adam(ae.parameters())\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    \n",
    "    return ae, criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979ae19e",
   "metadata": {
    "id": "3b05f1a5"
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbec9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_pipeline(training, testset_valid, holdout_valid, testset, holdout, data_description, triangular_banded_model, device, grid, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e768ff5d",
   "metadata": {
    "id": "233e278e"
   },
   "source": [
    "## Model: square root matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7625c5",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "1185f0f4"
   },
   "outputs": [],
   "source": [
    "class squarerootAE(nn.Module):\n",
    "    def __init__(self, n_items, n_ratings, hid1, hid2):\n",
    "        super(AE, self).__init__()\n",
    "        self.V = nn.Linear(n_items, hid1)\n",
    "        torch.nn.init.xavier_uniform_(self.V.weight)\n",
    "        self.W = nn.Linear(n_ratings, hid2)\n",
    "        torch.nn.init.xavier_uniform_(self.W.weight)\n",
    "        self.L = nn.Linear(n_ratings, n_ratings, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(self.L.weight)\n",
    "        self.norm = nn.LayerNorm(n_ratings)\n",
    "        self.vec = nn.Linear(n_ratings, 1)\n",
    "        torch.nn.init.xavier_uniform_(self.vec.weight)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        x = self.L(x)\n",
    "#         x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.W(x)\n",
    "        x = self.relu(x)\n",
    "        xT = torch.transpose(x, -1, -2)\n",
    "        yT = self.V(xT)\n",
    "        y = torch.transpose(yT, -1, -2)\n",
    "        y = self.relu(y)\n",
    "        # decode\n",
    "        output = torch.matmul(y, self.W.weight) + self.W.bias\n",
    "        output = self.relu(output)\n",
    "        outputT = torch.transpose(output, -1, -2)\n",
    "        outputT = torch.linalg.solve(self.L.weight, outputT)\n",
    "        outputT = self.relu(outputT)\n",
    "        outputT = torch.matmul(outputT, self.V.weight.T) + self.V.bias\n",
    "        output = torch.transpose(outputT, -1, -2)\n",
    "        # vec\n",
    "        output = self.vec(output).squeeze(-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2686621c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def square_root_model(h, data_description, device):\n",
    "    h1, h2 = h\n",
    "    ae = squarerootAE(data_description['n_items'], data_description['n_ratings'], h1, h2).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "    optimizer = optim.Adam(ae.parameters())\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    \n",
    "    return ae, criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70068ff",
   "metadata": {
    "id": "34cf52e8"
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c263b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_pipeline(training, testset_valid, holdout_valid, testset, holdout, data_description, square_root_model, device, grid, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c90e02",
   "metadata": {
    "id": "b7e34674"
   },
   "source": [
    "## Model: output -- tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a56f5c3",
   "metadata": {
    "id": "282778cf"
   },
   "outputs": [],
   "source": [
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, data, data_description):\n",
    "        useridx = data[data_description['users']].values\n",
    "        itemidx = data[data_description['items']].values\n",
    "        feedbackidx = data[data_description['feedback']].values\n",
    "        values = np.ones(len(itemidx), dtype=np.float32)\n",
    "        \n",
    "        self.tensor = torch.sparse_coo_tensor(np.array([useridx, itemidx, feedbackidx-1]), torch.tensor(values),\n",
    "                                            size=torch.Size((data_description[\"n_users\"], data_description[\"n_items\"], data_description['n_ratings'])))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensor.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tensor[idx], self.tensor[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ea4f97",
   "metadata": {
    "id": "bba737e2"
   },
   "outputs": [],
   "source": [
    "train_dataset = MVDataset(training, data_description)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448f9a7",
   "metadata": {
    "id": "26e4df1c"
   },
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, n_items, n_ratings, hid1, hid2, hid3):\n",
    "        super(AE, self).__init__()\n",
    "        self.V = nn.Linear(n_items, hid1)\n",
    "        self.W = nn.Linear(hid3, hid2)\n",
    "        self.L = nn.Linear(n_ratings, hid3)\n",
    "        triu_init(self.L)\n",
    "#         self.vec = nn.Linear(n_ratings, 1)\n",
    "#         self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        x = self.L(x)\n",
    "        x = self.W(x)\n",
    "        xT = torch.transpose(x, -1, -2)\n",
    "        yT = self.V(xT)\n",
    "        y = torch.transpose(yT, -1, -2)\n",
    "        # decode\n",
    "        output = torch.matmul(y, self.W.weight)\n",
    "        output = torch.matmul(output, self.L.weight)\n",
    "        output = torch.transpose(torch.matmul(torch.transpose(output, -1, -2), self.V.weight), -1, -2)\n",
    "        # vec\n",
    "#         output = self.tanh(output)\n",
    "#         output = self.vec(output).squeeze(-1)\n",
    "        return output\n",
    "\n",
    "ae = AE(data_description['n_items'], data_description['n_ratings'], 100, 50, 20).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = optim.Adam(ae.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3eb4df",
   "metadata": {
    "id": "947a9562",
    "outputId": "7d5a27d5-13cf-492e-905e-bbf28b2dfc17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x1fd4a6b6400>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones_like(ae.L.weight))\n",
    "# Register with hook\n",
    "ae.L.weight.register_hook(get_zero_grad_hook(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b2508",
   "metadata": {
    "id": "d66627e1",
    "outputId": "cec6f9e0-a566-4d83-c385-39457daacf16",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 0.05756956117039316\n",
      "epoch: 2 loss: 0.03614815729862072\n",
      "epoch: 3 loss: 0.03575290020987782\n",
      "epoch: 4 loss: 0.03627321601946479\n",
      "epoch: 5 loss: 0.03485188916437188\n",
      "epoch: 6 loss: 0.034166774960158026\n",
      "epoch: 7 loss: 0.03377212845626172\n",
      "epoch: 8 loss: 0.03298012822978059\n",
      "epoch: 9 loss: 0.03216922597101565\n",
      "epoch: 10 loss: 0.031279375748743725\n",
      "epoch: 11 loss: 0.030928388192607893\n",
      "epoch: 12 loss: 0.030600117746224342\n",
      "epoch: 13 loss: 0.030427866992069764\n",
      "epoch: 14 loss: 0.02986297190663743\n",
      "epoch: 15 loss: 0.029729154745765617\n",
      "epoch: 16 loss: 0.029318355819147626\n",
      "epoch: 17 loss: 0.02909153669179602\n",
      "epoch: 18 loss: 0.02883792771479945\n",
      "epoch: 19 loss: 0.028575731075128143\n",
      "epoch: 20 loss: 0.02832073374382789\n",
      "epoch: 21 loss: 0.02810518795184875\n",
      "epoch: 22 loss: 0.027664527045876793\n",
      "epoch: 23 loss: 0.02710385677798857\n",
      "epoch: 24 loss: 0.02677095800024293\n",
      "epoch: 25 loss: 0.025914379716449686\n",
      "epoch: 26 loss: 0.025117510825060727\n",
      "epoch: 27 loss: 0.024279714157379298\n",
      "epoch: 28 loss: 0.023368988862812298\n",
      "epoch: 29 loss: 0.022429407926534445\n",
      "epoch: 30 loss: 0.021635221282529475\n",
      "epoch: 31 loss: 0.02123053236219209\n",
      "epoch: 32 loss: 0.02049811686343803\n",
      "epoch: 33 loss: 0.019987538854560154\n",
      "epoch: 34 loss: 0.01965139297705688\n",
      "epoch: 35 loss: 0.019393759629643813\n",
      "epoch: 36 loss: 0.019125288470965646\n",
      "epoch: 37 loss: 0.018939571709752304\n",
      "epoch: 38 loss: 0.018771514640109482\n",
      "epoch: 39 loss: 0.018620242322847414\n",
      "epoch: 40 loss: 0.01867792561427038\n",
      "epoch: 41 loss: 0.01839956541786368\n",
      "epoch: 42 loss: 0.018200105457298096\n",
      "epoch: 43 loss: 0.018134815695133994\n",
      "epoch: 44 loss: 0.01801563190882293\n",
      "epoch: 45 loss: 0.017907986951091987\n",
      "epoch: 46 loss: 0.017931199018679532\n",
      "epoch: 47 loss: 0.017788184334067036\n",
      "epoch: 48 loss: 0.017848275357696893\n",
      "epoch: 49 loss: 0.01770472294242864\n",
      "epoch: 50 loss: 0.017489965414726052\n",
      "epoch: 51 loss: 0.017466925300853083\n",
      "epoch: 52 loss: 0.017445072146265138\n",
      "epoch: 53 loss: 0.017486963368784844\n",
      "epoch: 54 loss: 0.01736438022019544\n",
      "epoch: 55 loss: 0.017340221996890025\n",
      "epoch: 56 loss: 0.017296319719306317\n",
      "epoch: 57 loss: 0.01722366956135865\n",
      "epoch: 58 loss: 0.017143813607174804\n",
      "epoch: 59 loss: 0.017100146347273155\n",
      "epoch: 60 loss: 0.017047818129261334\n",
      "epoch: 61 loss: 0.01703116823029652\n",
      "epoch: 62 loss: 0.016978897953106\n",
      "epoch: 63 loss: 0.01691693907136216\n",
      "epoch: 64 loss: 0.01686823380280858\n",
      "epoch: 65 loss: 0.016880597755285016\n",
      "epoch: 66 loss: 0.01679025005116668\n",
      "epoch: 67 loss: 0.016825774288649082\n",
      "epoch: 68 loss: 0.016579750269539794\n",
      "epoch: 69 loss: 0.01630711600128631\n",
      "epoch: 70 loss: 0.0161405399089421\n",
      "epoch: 71 loss: 0.01611990880304843\n",
      "epoch: 72 loss: 0.015990834715444775\n",
      "epoch: 73 loss: 0.016044622034266983\n",
      "epoch: 74 loss: 0.01592706298902073\n",
      "epoch: 75 loss: 0.01586308198796118\n",
      "epoch: 76 loss: 0.01583338086406111\n",
      "epoch: 77 loss: 0.015803071931841668\n",
      "epoch: 78 loss: 0.01579385670948397\n",
      "epoch: 79 loss: 0.01573218980608752\n",
      "epoch: 80 loss: 0.015689605822584378\n",
      "epoch: 81 loss: 0.015940796058931936\n",
      "epoch: 82 loss: 0.015850538937270307\n",
      "epoch: 83 loss: 0.01566361217874657\n",
      "epoch: 84 loss: 0.015606591877377547\n",
      "epoch: 85 loss: 0.015588722830073218\n",
      "epoch: 86 loss: 0.015648861157564857\n",
      "epoch: 87 loss: 0.015669206614267735\n",
      "epoch: 88 loss: 0.015544931301393648\n",
      "epoch: 89 loss: 0.015589138248774888\n",
      "epoch: 90 loss: 0.015523264259588294\n",
      "epoch: 91 loss: 0.01553994244529625\n",
      "epoch: 92 loss: 0.01549999930717972\n",
      "epoch: 93 loss: 0.01543459091300654\n",
      "epoch: 94 loss: 0.015497855266577073\n",
      "epoch: 95 loss: 0.015439881203689155\n",
      "epoch: 96 loss: 0.015369810896475664\n",
      "epoch: 97 loss: 0.015361123088719357\n",
      "epoch: 98 loss: 0.015336239072127958\n",
      "epoch: 99 loss: 0.015313630264377995\n",
      "epoch: 100 loss: 0.015330087424915158\n"
     ]
    }
   ],
   "source": [
    "# Training the AE\n",
    "n_epochs = 100\n",
    "history = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):   \n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        user_tensor, true_user_tensor = batch\n",
    "        \n",
    "        input_tensor = user_tensor.to_dense().to(device)\n",
    "        target = true_user_tensor.to_dense().to(device)\n",
    "        \n",
    "        output = ae(input_tensor)\n",
    "        target.require_grad = False # we don't use it in training\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data.item()\n",
    "        \n",
    "    history.append(train_loss / len(train_dataloader))\n",
    "        \n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss / len(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4c09c",
   "metadata": {
    "id": "507dd8fc",
    "outputId": "e58c5e16-6869-4a3d-dcb5-0691780a6cd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fd54a21d00>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b175b7",
   "metadata": {
    "id": "64036a77",
    "outputId": "0124bb6e-841b-44de-d0d4-bcd1290f56c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.02183415055544881\n"
     ]
    }
   ],
   "source": [
    "# Testing the AE\n",
    "test_loss = 0\n",
    "\n",
    "for user in testset.userid.unique():\n",
    "    itemidx = testset.loc[testset.userid == user, data_description['items']].values\n",
    "    feedbackidx = testset.loc[testset.userid == user, data_description['feedback']].values\n",
    "    values = np.ones(len(itemidx), dtype=np.float32)\n",
    "\n",
    "    user_tensor_test = torch.sparse_coo_tensor(np.array([itemidx, feedbackidx-1]), torch.tensor(values),\n",
    "                              size=torch.Size((data_description[\"n_items\"], data_description['n_ratings']))).to_dense().to(device).unsqueeze(0)\n",
    "    target = user_tensor_test.clone()\n",
    "    \n",
    "    output = ae(user_tensor_test)\n",
    "    target.require_grad = False\n",
    "\n",
    "    loss = criterion(output, target)\n",
    "    test_loss += loss.data.item()\n",
    "    \n",
    "print('test loss: '+str(test_loss / testset.userid.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4976491",
   "metadata": {
    "id": "699a217e"
   },
   "outputs": [],
   "source": [
    "scores = torch.zeros((len(testset.userid.unique()), data_description['n_items']))\n",
    "for i, user in enumerate(testset.userid.unique()):\n",
    "    itemidx = testset.loc[testset.userid == user, data_description['items']].values\n",
    "    feedbackidx = testset.loc[testset.userid == user, data_description['feedback']].values\n",
    "    values = np.ones(len(itemidx), dtype=np.float32)\n",
    "\n",
    "    user_matrix_test = torch.sparse_coo_tensor(np.array([itemidx, feedbackidx-1]), torch.tensor(values),\n",
    "                              size=torch.Size((data_description[\"n_items\"], data_description['n_ratings']))).to_dense().unsqueeze(0).to(device)\n",
    "    \n",
    "    output = ae(user_matrix_test)\n",
    "    scores[i] = output[0][:, -1].T\n",
    "\n",
    "        \n",
    "scores = scores.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d174452d",
   "metadata": {
    "id": "1fe69f48",
    "outputId": "a86c67d8-b52d-4eb0-f2bb-2c8151568e01",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@5 = 0.0207, MRR@5 = 0.0097, Coverage@5 = 0.2287\n",
      "HR_pos@5 = 0.0196, HR_neg@5 = 0.0012\n",
      "MRR_pos@5 = 0.0089, MRR_neg@5 = 0.0007\n",
      "Matthews@5 = 0.0455\n",
      "-------------------------------------\n",
      "HR@10 = 0.0288, MRR@10 = 0.0107, Coverage@10 = 0.2981\n",
      "HR_pos@10 = 0.0265, HR_neg@10 = 0.0023\n",
      "MRR_pos@10 = 0.0098, MRR_neg@10 = 0.0009\n",
      "Matthews@10 = 0.0427\n",
      "-------------------------------------\n",
      "HR@20 = 0.0454, MRR@20 = 0.0119, Coverage@20 = 0.4004\n",
      "HR_pos@20 = 0.0431, HR_neg@20 = 0.0023\n",
      "MRR_pos@20 = 0.0110, MRR_neg@20 = 0.0009\n",
      "Matthews@20 = 0.0711\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.010699453252644743, 0.02875215641173088, 0.042746208372664046)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our\n",
    "downvote_seen_items(scores, testset, data_description)\n",
    "make_prediction(scores, holdout, data_description)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "621.778px",
    "left": "651px",
    "top": "110.806px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0220759f642b49e0bdf1a9046b3034eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0592a95212db40fc9d382d1fb3b49cce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0618494bb5ed43acb878024d8c1597ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "081356837cc543449ef2f5152f604d8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09d177dba8f043e0864f84db7b1534a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c8262c33e5a4c0986516231c72fcdbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c18a00209e524324acc12062da6fb4da",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0220759f642b49e0bdf1a9046b3034eb",
      "value": 13
     }
    },
    "2ca4069a4cac4bf0b78fca9e1995f1b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4bf9327158b04457b6898dc26c85c84d",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eb785688049641d2a86bb3e2e79aa85c",
      "value": 8
     }
    },
    "325615a06b3043bd88e8c18fcb69d2d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3942c4971620426091dee458a697bce1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_57cb8d07f2ca4c3c97e9024afb834628",
       "IPY_MODEL_2ca4069a4cac4bf0b78fca9e1995f1b9",
       "IPY_MODEL_eb523faa4d5c4018b7b089ce1cca6b8f"
      ],
      "layout": "IPY_MODEL_92e67bf006814252852d09e47e6e57b5"
     }
    },
    "3a2f59a883cd4c63b6752394f481ae0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bac83d90458d498a9b3cf4aead4dfb17",
       "IPY_MODEL_97c252d659a34c27bec786db4eac3ef1",
       "IPY_MODEL_9de1ab42e06d459c99caa19717b30b90"
      ],
      "layout": "IPY_MODEL_441ef8398b6e48e59fba5f8f7d6dd4de"
     }
    },
    "410a090e678d49168fa1aa6d1d48236c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "441ef8398b6e48e59fba5f8f7d6dd4de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48b33c08d87b42348fc39cc1019d0c33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bf9327158b04457b6898dc26c85c84d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "538ca76dacd64f0c8bc64914f574b2b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57cb8d07f2ca4c3c97e9024afb834628": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0618494bb5ed43acb878024d8c1597ee",
      "placeholder": "",
      "style": "IPY_MODEL_0592a95212db40fc9d382d1fb3b49cce",
      "value": " 38%"
     }
    },
    "72905fce21ac40a0b57d937532c0e1f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92e67bf006814252852d09e47e6e57b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97c252d659a34c27bec786db4eac3ef1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72905fce21ac40a0b57d937532c0e1f3",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e157a0344ec047ec94646295ffabe550",
      "value": 9
     }
    },
    "9ac3af6112564b72866bda1f241c7a3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9de1ab42e06d459c99caa19717b30b90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b28284d9f185409daeff164318e9fa4d",
      "placeholder": "",
      "style": "IPY_MODEL_a0de85cd7972446eba01aa8146670617",
      "value": " 9/21 [2:45:33&lt;3:41:37, 1108.13s/it]"
     }
    },
    "a0de85cd7972446eba01aa8146670617": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6af49b49dad4aa6a7ef5ade0b4db909": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4f3797a8e7e44dfac35003d70ecbcd2",
      "placeholder": "",
      "style": "IPY_MODEL_9ac3af6112564b72866bda1f241c7a3b",
      "value": " 62%"
     }
    },
    "b28284d9f185409daeff164318e9fa4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4f3797a8e7e44dfac35003d70ecbcd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6e1a9fdf93c46bb824b549bbfc23478": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a6af49b49dad4aa6a7ef5ade0b4db909",
       "IPY_MODEL_1c8262c33e5a4c0986516231c72fcdbb",
       "IPY_MODEL_eefdd3a819024cd894609d743261aa4f"
      ],
      "layout": "IPY_MODEL_48b33c08d87b42348fc39cc1019d0c33"
     }
    },
    "bac83d90458d498a9b3cf4aead4dfb17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_538ca76dacd64f0c8bc64914f574b2b8",
      "placeholder": "",
      "style": "IPY_MODEL_325615a06b3043bd88e8c18fcb69d2d9",
      "value": " 43%"
     }
    },
    "c18a00209e524324acc12062da6fb4da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e157a0344ec047ec94646295ffabe550": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eb523faa4d5c4018b7b089ce1cca6b8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_081356837cc543449ef2f5152f604d8f",
      "placeholder": "",
      "style": "IPY_MODEL_09d177dba8f043e0864f84db7b1534a1",
      "value": " 8/21 [5:01:09&lt;10:02:15, 2779.64s/it]"
     }
    },
    "eb785688049641d2a86bb3e2e79aa85c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eefdd3a819024cd894609d743261aa4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_410a090e678d49168fa1aa6d1d48236c",
      "placeholder": "",
      "style": "IPY_MODEL_f9241968c22542919e8fdadaf14c4cfe",
      "value": " 13/21 [3:12:09&lt;2:24:24, 1083.11s/it]"
     }
    },
    "f9241968c22542919e8fdadaf14c4cfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
